---
title: "[#2] 📘 하둡의 핵심 구성요소와 실습 과정"
tags:
    - Apache
    - Hadoop
    - Study
date: "2025-02-15"
thumbnail: "/assets/img/thumbnail/hadoop_basic.png"
bookmark: true
---

저번 포스팅에서는, 하둡이 어떻게 등장했는지를 공부하고 정리해봤습니다.

[📘 분산 시스템의 이해와 하둡의 등장 배경](https://jeondaehong.github.io/%F0%9F%93%96%20%EA%B0%9C%EC%9D%B8%20%EA%B3%B5%EB%B6%80/%F0%9F%91%89%20Apache%20Hadoop/1.%20%EB%B6%84%EC%82%B0%20%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%20%EC%9D%B4%ED%95%B4%EC%99%80%20%ED%95%98%EB%91%A1%EC%9D%98%20%EB%93%B1%EC%9E%A5%20%EB%B0%B0%EA%B2%BD.html)

<br>

# 🐘 1. HDFS

HDFS 는 Hadoop 의 핵심 아키텍처 중 하나입니다.

HDFS 의 아키텍처에도 따로 Block File System, NameNode, DataNode 등이 있습니다.

HDFS 가 무엇인지를 본격적으로 알아보기 전에, HDFS 가 어떤 철학과 목표를 가지고 만들어졌는지, 그 특징은 무엇인지를 간단하게 공부하고 넘어가겠습니다.

**① HDFS 는 하드웨어 장애에 대처할 수 있어야 합니다.**
HDFS를 구성하는 분산 서버에는 다양한 장애가 발생할 수 있습니다.
예를 들면 하드디스크에 오류가 생겨서 데이터 저장에 실패하는 경우, 디스크 복구가 불가능해 데이터가 유실되는 경우, 네트워크 장애가 생겨 특정 분산 서버에 네트워크 접근이 안되는 경우 등이 있을 수 있습니다.
HDFS는 이런 장애를 빠른 시간에 감지하고 대처할 수 있게 설계되어 있습니다.
HDFS에 데이터를 저장하면, 복제본도 함께 저장되어 데이터 유실을 방지하며, 분산 서버 사이에는 주기적으로 health check 를 통해 빠른 시간에 장애를 감지하고 대처할 수 있게 됩니다.


**② HDFS 는 Streaming 식 데이터 접근에 최적화 되어있습니다.**
HDFS는 사용자 요청을 빠르게 처리하는 것보다 동일 시간 내에 더 많은 데이터를 안정적으로 처리하는 데 중점을 둡니다.
따라서 중간부터 읽고, 쓰는 Random Access 방식보다는 처음부터 순차적으로 읽어가는 Streaming 방식에 최적화되어 있습니다.
가끔 이 Streaming 방식이 카프카처럼 실시한 데이터 스트리밍과 헷갈릴 수 있는데, 그런 스트리밍을 의미하는것이 아니라, 처음부터 끝까지 순차적으로 데이터를 읽는데에 특화되었다는 의미입니다.
이런 방식으로 인해 사용자와 상호작용이 많은 트랜잭션 기반 서비스(예: 인터넷 뱅킹, 쇼핑몰 등)보다는 대규모 데이터를 일괄 처리하는 배치 처리(batch processing)에 더 적합합니다.

**③ HDFS 는 대용량 데이터셋 처리에 유리합니다.**
HDFS는 하나의 파일이 수 기가바이트(GB)에서 수 테라바이트(TB)에 이르는 크기로 저장될 수 있도록 설계되어 있습니다.
이를 통해 높은 **데이터 전송 대역폭(bandwidth)**을 지원하며, 수백 대의 노드로 구성된 클러스터를 효율적으로 운영할 수 있습니다. HDFS는 단일 인스턴스에서 수천만 개 이상의 파일을 관리할 수 있습니다.
여기서 말하는 데이터 전송 대역폭은, 한 번에 얼마나 많은 데이터를 빠르게 보낼 수 있는가를 의미합니다.

**④ HDFS 는 하드웨어 장애에 대처할 수 있어야 합니다.**

**⑤ HDFS 는 하드웨어 장애에 대처할 수 있어야 합니다.**

**⑥ HDFS 는 하드웨어 장애에 대처할 수 있어야 합니다.**


## 🐘 1.1. Block File System
---
하둡은 Block File System 입니다. 즉, 블록 형태로 파일을 저장합니다.




## 🐘 1.2. NameNode 와 DataNode
---


## 🐘 1.3. Secondary NameNode
---


## 🐘 1.4. Read 와 Write 시 내부에서 벌어지는 일
---

<br>
<br>
<div align="center">◈</div>
<br>

# 🐘 2. Hadoop H/A 클러스터

## 🐘 2.1. 클러스터 구성 위해 잠시 짚어갈 Zookeeper
---


## 🐘 2.2. Quorum Journal Nodes H/A
---


## 🐘 2.3. Shared Storage H/A
---


## 🐘 2.4. Automatic Failover
---


## 🐘 2.5. Observer Name Node ( ONN )
---

<br>
<br>
<div align="center">◈</div>
<br>

# 🐘 3. Eraser Coding

## 🐘 3.1. Software Eraser Coding
---

## 🐘 3.2. Hardware Eraser Coding
---

## 🐘 3.3. 하둡에서의 Eraser Coding
---

<br>
<br>
<div align="center">◈</div>
<br>

# 🐘 4. YARN

## 🐘 4.1. YARN 이란
---

## 🐘 4.2. YARN 아키텍처
---

### 🐘 4.2.1. 기본 아키텍처

### 🐘 4.2.2. Resource Mananger

### 🐘 4.2.3. Node Manager


## 🐘 4.3. YARN 의 작업 흐름
---

### 🐘 4.3.1. High Level Workflow

### 🐘 4.3.2. Application 실행 요청

### 🐘 4.3.3. Application Master 실행 요청

### 🐘 4.3.4. Application Master 등록

### 🐘 4.3.5. 컨테이너 실행

### 🐘 4.3.6. Application Master 종료

### 🐘 4.3.7. Auxiliary Service


## 🐘 4.4. Fair Call Queue 와 FIFO Queue
---

## 🐘 4.5. YARN 실습
---

<br>
<br>
<div align="center">◈</div>
<br>

# 🐘 5. Map Reduce

## 🐘 5.1. Map Reduce 란
---

## 🐘 5.2. Map Reduce 기능과 프로그래밍
---

## 🐘 5.3. Map Reduce 실습
---

## 🐘 5.4. Map Reduce 의 한계
---

## 🐘 5.5. Cascading
---

<br>
<br>
<div align="center">◈</div>
<br>

# ✏️ 결론

<br>
<br>
<div align="center">◈</div>
<br>

# 📚 공부 참고 자료