---
title: "📘 Map Reduce 기본 이론과 실습"
tags:
    - Apache
    - Hadoop
    - Study
date: "2025-03-30"
thumbnail: "/assets/img/thumbnail/hadoop_basic_6.png"
bookmark: true
---

저번 포스팅에서는, YARN 에 대하여 공부하였습니다.
이번에는 하둡의 핵심 요소 중 하나인 Map Reduce 에 대하여 공부한 내용을 포스팅하겠습니다.

[📘 분산 시스템의 이해와 하둡의 등장 배경](https://jeondaehong.github.io/%F0%9F%93%96%20%EA%B0%9C%EC%9D%B8%20%EA%B3%B5%EB%B6%80/%F0%9F%91%89%20Apache%20Hadoop/1.%20%EB%B6%84%EC%82%B0%20%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%20%EC%9D%B4%ED%95%B4%EC%99%80%20%ED%95%98%EB%91%A1%EC%9D%98%20%EB%93%B1%EC%9E%A5%20%EB%B0%B0%EA%B2%BD.html)
[📘 하둡의 핵심 구성요소와 이론](https://jeondaehong.github.io/%F0%9F%93%96%20%EA%B0%9C%EC%9D%B8%20%EA%B3%B5%EB%B6%80/%F0%9F%91%89%20Apache%20Hadoop/2.%20%ED%95%98%EB%91%A1%EC%9D%98%20%ED%95%B5%EC%8B%AC%20%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C%EC%99%80%20%EC%9D%B4%EB%A1%A0.html)
[📘 YARN(Yet Another Resource Negotiator) 기본 이론](https://jeondaehong.github.io/%F0%9F%93%96%20%EA%B0%9C%EC%9D%B8%20%EA%B3%B5%EB%B6%80/%F0%9F%91%89%20Apache%20Hadoop/3.%20YARN(Yet%20Another%20Resource%20Negotiator)%20%EA%B8%B0%EB%B3%B8%20%EC%9D%B4%EB%A1%A0.html)

<br>
<br>
<div align="center">◈</div>
<br>


# 🐘 1. Map Reduce

MapReduce는 대용량 데이터를 분산 환경에서 효율적으로 처리하기 위한 병렬 처리 프로그래밍 모델입니다.
이 모델은 원래 2004년 구글에서 발표되었으며, Apache Hadoop은 이를 오픈소스 프레임워크로 구현하였습니다.
Hadoop의 MapReduce는 특히 HDFS와 함께 사용되어, 수백 GB에서 수 PB 규모의 데이터를 여러 대의 컴퓨터에 나눠 처리할 수 있도록 설계되었습니다.

MapReduce는 데이터를 Key-Value 형태로 가공하며, 처리 과정은 크게 Map 단계와 Reduce 단계로 나뉩니다.
Map 단계에서는 데이터를 분할하고 병렬로 처리하며, Reduce 단계에서는 그 결과를 수집하고 통합합니다.

이 구조 덕분에 개발자는 복잡한 병렬 분산 환경을 신경 쓰지 않고, 데이터 처리 로직만 구현하면 됩니다.

<br>
## 🐘 1.1. MapReduce 알고리즘
---
MapReduce는 크게 두 가지 함수로 구성되어 있습니다.

- **Map Function**  
  입력 데이터를 `(key1, value1)` 형태로 받아, 이를 `(key2, value2)` 형태의 중간 결과로 변환합니다.
  
  `(key1, value1) → (key2, value2)`
  
- **Reduce Function**  
  Map 단계에서 생성된 중간 결과들을 key 기준으로 그룹화한 뒤, 같은 key를 갖는 값들의 리스트를 받아 최종 결과 `(key3, value3)`을 생성합니다.

  `(key2, List<value2>) → (key3, value3)`

<br>
## 🐘 1.2. Map Reduce 1.0
---

### 🐘 1.2.1. Hadoop 1.x에서의 MapReduce 구성 요소

Hadoop 1.x에서는 클래식 MapReduce 모델을 사용하며, 다음과 같은 주요 컴포넌트로 구성됩니다.

  1. **JobTracker (1개):**
     클러스터 전체에서 Job의 실행을 총괄하는 마스터 역할을 합니다.
     클라이언트로부터 Job을 받아 Task로 나누고, 적절한 TaskTracker에게 분배합니다.

  2. **TaskTracker (여러 개):**
     각각의 노드에 존재하며, JobTracker로부터 Task를 할당받아 실제로 Map 또는 Reduce 작업을 수행합니다.

  3. **Client:**
     사용자가 직접 작성한 MapReduce Job을 hadoop jar 명령어로 실행하면, 이 Job을 제출하는 주체가 됩니다.

  4. **HDFS:**
     Job 실행 중 사용되는 입력 파일, 중간 파일, 출력 파일 등은 모두 HDFS 상에 저장됩니다.
     Mapper/Reducer 간의 데이터 공유도 HDFS를 통해 수행됩니다.

<br>
### 🐘 1.2.2. MapReduce는 언제 동작하는가?

MapReduce는 단순한 파일 업로드, 다운로드, 삭제와 같은 명령어에서는 동작하지 않습니다.
즉, `hdfs dfs -put`, `-get`, `-ls`, `-rm` 같은 명령어를 사용할 때는 **MapReduce**가 관여하지 않으며,
이 경우 HDFS 클라이언트가 직접 NameNode와 DataNode에 요청을 보내 처리합니다.

반면, 다음과 같은 경우에는 MapReduce 엔진이 실제로 Job을 실행합니다.

- hadoop jar로 실행한 MapReduce 프로그램

- Hive, Pig, Oozie 등에서 MapReduce 백엔드를 사용하는 쿼리 실행

- Sqoop import/export 작업

- 기타 사용자 정의 분석 Job

<br>
이처럼 MapReduce는 “분산 처리 Job”이 필요한 경우에만 실행됩니다.

<br>
## 🐘 1.3. Map Reduce 2.0
---

## 🐘 1.4. Map Reduce 기능과 프로그래밍 실습
---

## 🐘 1.5. Map Reduce 의 한계
---

## 🐘 1.6. Cascading
---

<br>
<br>
<div align="center">◈</div>
<br>

# ✏️ 결론

<br>
<br>
<div align="center">◈</div>
<br>

# 📚 공부 참고 자료