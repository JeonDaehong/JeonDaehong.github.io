---
title: "📘 Map Reduce 기본 이론과 실습"
tags:
    - Apache
    - Hadoop
    - Study
date: "2025-03-30"
thumbnail: "/assets/img/thumbnail/hadoop_basic_6.png"
bookmark: true
---

저번 포스팅에서는, YARN 에 대하여 공부하였습니다.
이번에는 하둡의 핵심 요소 중 하나인 Map Reduce 에 대하여 공부한 내용을 포스팅하겠습니다.

[📘 분산 시스템의 이해와 하둡의 등장 배경](https://jeondaehong.github.io/%F0%9F%93%96%20%EA%B0%9C%EC%9D%B8%20%EA%B3%B5%EB%B6%80/%F0%9F%91%89%20Apache%20Hadoop/1.%20%EB%B6%84%EC%82%B0%20%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%20%EC%9D%B4%ED%95%B4%EC%99%80%20%ED%95%98%EB%91%A1%EC%9D%98%20%EB%93%B1%EC%9E%A5%20%EB%B0%B0%EA%B2%BD.html)
[📘 하둡의 핵심 구성요소와 이론](https://jeondaehong.github.io/%F0%9F%93%96%20%EA%B0%9C%EC%9D%B8%20%EA%B3%B5%EB%B6%80/%F0%9F%91%89%20Apache%20Hadoop/2.%20%ED%95%98%EB%91%A1%EC%9D%98%20%ED%95%B5%EC%8B%AC%20%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C%EC%99%80%20%EC%9D%B4%EB%A1%A0.html)
[📘 YARN(Yet Another Resource Negotiator) 기본 이론](https://jeondaehong.github.io/%F0%9F%93%96%20%EA%B0%9C%EC%9D%B8%20%EA%B3%B5%EB%B6%80/%F0%9F%91%89%20Apache%20Hadoop/3.%20YARN(Yet%20Another%20Resource%20Negotiator)%20%EA%B8%B0%EB%B3%B8%20%EC%9D%B4%EB%A1%A0.html)

<br>
<br>
<div align="center">◈</div>
<br>


# 🐘 1. Map Reduce

MapReduce는 대용량 데이터를 분산 환경에서 효율적으로 처리하기 위한 병렬 처리 프로그래밍 모델입니다.
이 모델은 원래 2004년 구글에서 발표되었으며, Apache Hadoop은 이를 오픈소스 프레임워크로 구현하였습니다.
Hadoop의 MapReduce는 특히 HDFS와 함께 사용되어, 수백 GB에서 수 PB 규모의 데이터를 여러 대의 컴퓨터에 나눠 처리할 수 있도록 설계되었습니다.

MapReduce는 데이터를 Key-Value 형태로 가공하며, 처리 과정은 크게 Map 단계와 Reduce 단계로 나뉩니다.
Map 단계에서는 데이터를 분할하고 병렬로 처리하며, Reduce 단계에서는 그 결과를 수집하고 통합합니다.

이 구조 덕분에 개발자는 `Map`과 `Reduce` 함수만 정의하면 되고, 나머지 작업(Job 분할, Task 배정, 장애 복구 등)은 Hadoop이 자동으로 처리합니다.

또한 Java를 기본으로 하지만, C++, Python 등 다양한 언어도 지원됩니다 (예: Hadoop Streaming 사용 시).
  
따라서 개발자는 인프라 걱정 없이 비즈니스 로직 구현에 집중할 수 있습니다.

<br>
## 🐘 1.1. MapReduce 알고리즘과 구동방식
---
MapReduce는 크게 두 가지 함수로 구성되어 있습니다.

- **📌 Map Function**  
  입력 데이터를 `(key1, value1)` 형태로 받아, 이를 `(key2, value2)` 형태의 중간 결과로 변환합니다.
  
  ***ex : (key1, value1) → (key2, value2)***
  
- **📌 Reduce Function**  
  Map 단계에서 생성된 중간 결과들을 key 기준으로 그룹화한 뒤, 같은 key를 갖는 값들의 리스트를 받아 최종 결과 `(key3, value3)`을 생성합니다.

  ***ex : (key2, List<value2>) → (key3, value3)***
  
이러한 두 단계를 통해 데이터는 **분산 환경에서 병렬로 처리**되며, 최종적으로 집계 및 가공된 결과를 얻게 됩니다.

또한 MapReduce 의 구동 방식은 크게 세 가지입니다.

- **🔹 Local**
  단일 JVM 에서 전체 Job 을 실행하는 방식으로, 테스트 용도 정도로만 쓰이지 실제로는 이러한 방식으로 운영하지 않습니다.

- **🔹 Classic**
  Hadoop 1.0 버전때까지 유지하던 Map Reduce 분산 처리 방식이며, 1개의 Job Tracker 와 여러개의 Task Tracker 를 사용하는 초기 Map Reduce 방식입니다.

- **🔹 YARN**
  Hadoop 2.0 YARN 도움 이후의 Map Reduce 방식입니다. Map Reduce 이외의 워크로드도 수용이 가능한 버전입니다.

이러한 Map Reduce 는, 단순하고 사용이 편리하며, 특정 데이터 모델이나 스키마에 의존적이지 않은 유연성을 가지고 있고, 저장 구조도 독립적입니다. 또한 데이터 복제에 기반한 내구성과 자체 재시도 로직을 통한 내고장성도 확보하고 있으며, 하둡을 활용한 높은 확장성을 가지고 있다는 장점이 있습니다.

그러나, 고정된 단일 데이터 흐름을 가지고 있고, Hive 등이 있지만 여전히 DBMS 보다는 불편한 스키마 질의, 그리고 작업 데이터를 처리하기에 적합하지 않고, 기술 지원이 어렵다는 단점등을 가지고 있습니다.

그럼 지금부터, MapReduce 에 대해 좀 더 자세히 공부한 내용을 정리해보겠습니다.

<br>
## 🐘 1.2. Map Reduce 1.0 & 기본
---

파트를 1.0 과 2.0 으로 나누기는 하였지만, Map Reduce 1.0 과 2.0 이 크게 차이가 있지는 않습니다.

어느정도 단점을 보완해주고, YARN 을 통해 구동하는가 안하는거 정도라고 할 수 있습니다.

그래서 현재 1.2 파트에서는 1.0과 현재 Map Reduce 의 기본이 되는 부분을 공부하고 정리하였습니다.

다음 파트인 MapReduce 2.0 에서는 변동사항만 정리할 예정입니다.

<br>
### 🐘 1.2.1. Hadoop 1.x에서의 MapReduce 구성 요소

Hadoop 1.x에서는 클래식 MapReduce 모델을 사용하며, 다음과 같은 주요 컴포넌트로 구성됩니다.

  1. **JobTracker (1개):**
     클러스터 전체에서 Job의 실행을 총괄하는 마스터 역할을 합니다.
     클라이언트로부터 Job을 받아 Task로 나누고, 적절한 TaskTracker에게 분배합니다.

  2. **TaskTracker (여러 개):**
     각각의 노드에 존재하며, JobTracker로부터 Task를 할당받아 실제로 Map 또는 Reduce 작업을 수행합니다.

  3. **Client:**
     사용자가 직접 작성한 MapReduce Job을 hadoop jar 명령어로 실행하면, 이 Job을 제출하는 주체가 됩니다.

  4. **HDFS:**
     Job 실행 중 사용되는 입력 파일, 중간 파일, 출력 파일 등은 모두 HDFS 상에 저장됩니다.
     Mapper/Reducer 간의 데이터 공유도 HDFS를 통해 수행됩니다.

<br>
### 🐘 1.2.2. MapReduce는 언제 동작하는가?

MapReduce는 단순한 파일 업로드, 다운로드, 삭제와 같은 명령어에서는 동작하지 않습니다.
즉, `hdfs dfs -put`, `-get`, `-ls`, `-rm` 같은 명령어를 사용할 때는 **MapReduce**가 관여하지 않으며,
이 경우 HDFS 클라이언트가 직접 NameNode와 DataNode에 요청을 보내 처리합니다.

반면, 다음과 같은 경우에는 MapReduce 엔진이 실제로 Job을 실행합니다.

- hadoop jar로 실행한 MapReduce 프로그램

- Hive, Pig, Oozie 등에서 MapReduce 백엔드를 사용하는 쿼리 실행

- Sqoop import/export 작업

- 기타 사용자 정의 분석 Job

이처럼 MapReduce는 **“분산 처리 Job”**이 필요한 경우에만 실행됩니다.


<br>
### 🐘 1.2.3. MapReduce Task 구동 절차

<img src="/assets/img/mapreduce1.jpg" alt="MapReduce" style="border: 2px solid skyblue; border-radius: 4px;" />

<br>
> 출처 : [Map Reduce 1.0 상세 구동 절차](https://cocoa-t.tistory.com/entry/%EA%B0%9C%EB%85%90-%EC%A0%95%EB%A6%AC-%ED%95%98%EB%91%A1-%EB%A7%B5%EB%A6%AC%EB%93%80%EC%8A%A4MapReduce-%EC%9D%B4%ED%95%B4)

<br>

1. **사용자 애플리케이션 실행**  
   사용자가 클라이언트에서 MapReduce 프로그램을 실행하면, 내부적으로 `JobClient`가 생성되고 실행됩니다.

2. **Job ID 발급 요청**  
   JobClient는 클러스터의 **JobTracker**에 연결하여 새로운 Job ID를 요청합니다.

3. **Job 리소스 HDFS 업로드**  
   실행에 필요한 코드, 설정 파일, 라이브러리 등을 HDFS에 업로드합니다.

4. **JobTracker에 Job 제출**  
   JobClient는 JobTracker에게 Job을 제출하며, 이후 작업 스케줄링은 JobTracker가 관리합니다.

5. **Job 초기화**  
   JobTracker는 제출된 Job에 대한 초기화 작업을 수행합니다 (메타정보 구성, 디렉터리 생성 등).

6. **InputSplit 검색**  
   HDFS에서 입력 데이터를 블록 단위로 나눈 후, 각 블록의 위치 정보를 기준으로 `InputSplit`을 구성합니다.
   InputSplits 는, 물리적 Block 들을 논리적으로 그루핑 한 개념이라고 볼 수 있습니다.
   InputSplit 은 Mapper 의 입력 데이터를 분할하는 방식을 제공하기 위해, 데이터 위치와 읽어 들이는 길이를 정의합니다.

7. **Task 할당 요청 (Heartbeat)**  
   TaskTracker는 주기적으로 JobTracker에 하트비트를 보내며, 실행 가능한 Task가 있는지 확인합니다.

8. **Job 리소스 로컬 복사**  
   Task가 할당되면, TaskTracker는 HDFS에서 필요한 Job 리소스를 자신의 로컬 디렉터리로 복사합니다.

9. **Child JVM 실행**  
   TaskTracker는 자식 JVM 프로세스를 생성하여, Map 또는 Reduce Task를 실행할 준비를 합니다.

10. **Map 또는 Reduce Task 실행**  
    할당받은 Task를 실행하여 실제 데이터 처리(Map 또는 Reduce 로직)를 수행합니다.

<br>
> **💬 참고:** 위 절차는 Hadoop 1.x (MapReduce v1) 기준입니다.  
> Hadoop 2.x 이상에서는 YARN이 도입되며 JobTracker/TaskTracker가 ResourceManager/NodeManager로 대체됩니다.

<br>
### 🐘 1.2.4. MapReduce 동작 과정

MapReduce 는 다음 6가지 동작 과정을 가집니다.

1. 입력 데이터 분할 (Input Splitting)
   - 대용량 입력 파일을 여러 개의 **Input Split**으로 나눕니다.  
   - 각 Split은 병렬로 처리할 수 있는 최소 단위입니다.  
   - 보통 HDFS 블록 크기(예: 128MB)를 기준으로 나뉩니다.
   
2. 맵(Map) 단계
   - 각 Input Split에 대해 **Map 함수**가 병렬로 실행됩니다.  
   - Map 함수는 입력 데이터를 키-값 쌍 (key-value pair)으로 변환합니다.  
   - 예를 들어, 텍스트 파일을 줄 단위로 읽어 단어별로 `(단어, 1)` 쌍을 만듭니다.  
   - Map 함수 결과는 메모리 버퍼에 임시 저장됩니다.

3. 중간 정렬 및 병합 (Sort and Merge)
   - Map 출력 결과는 내부에서 키를 기준으로 정렬됩니다.  
   - 정렬된 결과는 디스크에 임시 저장되며, 여러 Map 결과를 병합(merge)합니다.  
   - 이 단계는 후속 작업인 Shuffle을 원활하게 만듭니다.

4. 셔플(Shuffle)
   - 각 Mapper에서 정렬된 데이터를 **Reducer**로 전송합니다.  
   - 동일한 키를 가진 모든 값이 하나의 Reducer에 모이도록 데이터를 네트워크로 이동시킵니다.  
   - 이 과정은 Map과 Reduce 작업의 중간 단계로 네트워크 I/O를 많이 발생시킵니다.

5. 리듀스(Reduce) 단계
   - Reducer는 전달받은 키별로 그룹화된 값을 입력받아 집계 연산을 수행합니다.  
   - 예를 들어, `(단어, [1,1,1,...])` 값을 받아 단어 등장 횟수를 합산합니다.  
   - Reduce 함수 결과는 최종 출력(key-value 쌍)으로 생성됩니다.

6. 결과 저장 (Output)
   - Reduce 작업의 결과는 HDFS 같은 분산 파일 시스템에 저장됩니다.  
   - 출력 파일은 여러 파티션으로 나누어 저장될 수 있습니다.

요약해보면, 아래 표처럼 볼 수 있겠습니다.

| 단계             | 설명                                  |
|------------------|-------------------------------------|
| 1. 입력 분할     | 데이터를 여러 Split으로 나눔          |
| 2. 맵(Map)       | 각 Split에 대해 Map 함수 실행          |
| 3. 정렬 및 병합  | Map 결과를 키별로 정렬, 병합           |
| 4. 셔플(Shuffle) | 키별로 데이터를 Reducer에 전송          |
| 5. 리듀스(Reduce)| 키별로 집계 작업 수행                  |
| 6. 출력 저장     | 최종 결과를 분산 파일 시스템에 저장     |

<br>
### 🐘 1.2.5. MapReduce 예시

<img src="/assets/img/mapreduce3.jpg" alt="MapReduce" style="border: 2px solid skyblue; border-radius: 4px;" />

<br>
> 출처 : [Map Reduce 예시](https://cocoa-t.tistory.com/entry/%EA%B0%9C%EB%85%90-%EC%A0%95%EB%A6%AC-%ED%95%98%EB%91%A1-%EB%A7%B5%EB%A6%AC%EB%93%80%EC%8A%A4MapReduce-%EC%9D%B4%ED%95%B4)

<br>

1. **입력 데이터 분할 (Input Splitting)**  
   100GB짜리 텍스트 파일이 있다고 합시다. 이 파일은 HDFS에 저장되고, 128MB 크기 단위로 쪼개집니다.  
   각 128MB 조각 하나가 하나의 Input Split이 됩니다.

2. **맵(Map) 단계**  
   각 Input Split은 별도의 Map Task에 할당되어 병렬로 처리됩니다.  
   Map 함수는 텍스트를 줄 단위로 읽고, 각 줄에서 단어를 분리해 `(단어, 1)` 쌍을 생성합니다.  
   예를 들어, 한 줄에 “Andy and Bob”이 있으면 `(Andy, 1)`, `(and, 1)`, `(Bob, 1)` 이런 식입니다.  
   이렇게 모든 단어에 대해 1씩 붙여서 중간 결과를 만듭니다.

3. **중간 정렬 및 병합 (Sort & Merge)**  
   각 Map Task가 만든 `(단어, 1)` 쌍들은 키(단어) 기준으로 내부 정렬됩니다.  
   메모리 버퍼가 차면 디스크에 spill 하여 임시 저장되고, 여러 번 spill된 데이터는 하나로 병합됩니다.  
   이 과정 덕분에 후속 작업인 Shuffle이 효율적으로 진행됩니다.

4. **셔플(Shuffle)**  
   각 Map Task가 정렬한 단어별 데이터를, 동일한 단어를 처리할 Reduce Task로 네트워크를 통해 전송합니다.  
   즉, “Andy”에 해당하는 모든 `(Andy, 1)` 데이터는 특정 Reduce Task로 모입니다.  
   이 단계는 Map과 Reduce 사이에서 데이터를 재분배하는 중요한 과정입니다.

5. **리듀스(Reduce) 단계**  
   Reduce Task는 한 단어에 대한 모든 1들의 리스트를 전달받아 합계를 계산합니다.  
   예를 들어, `(Andy, [1, 1, 1, 1])`이면 최종적으로 `(Andy, 4)`가 됩니다.  
   이 계산을 모든 단어에 대해 수행합니다.

6. **결과 저장 (Output)**  
   최종 `(단어, 총횟수)` 결과들은 HDFS 같은 분산 파일 시스템에 저장됩니다.  
   결과 파일들은 여러 개의 파티션으로 나뉠 수 있습니다.

MapReduce 의 해당 과정을 통해, 수백 GB 텍스트 파일에서도 단어별 등장 횟수를 효율적으로 셀 수 있습니다.

<br>

### 🐘 1.2.6. MapReduce 예시 구현을 위한 인터페이스

MapReduce는 다음과 같은 인터페이스 흐름을 통해 입력 데이터를 처리하고 출력까지 생성합니다:

- ***Input → Mapper → Combiner(선택 사항) → Partitioner → Shuffle/Sort → Reducer → Output***

**🔹 Input: `TextInputFormat`**
입력 데이터를 `(k1, v1)` 형태로 읽어오는 역할을 합니다. 보통 `k1`은 **byte offset**, `v1`은 **텍스트 줄(String)**입니다. 입력 포맷은 데이터 구조에 따라 달라질 수 있습니다.

<br>
**🔹 Mapper: `(k1, v1) → (k2, v2)`**
핵심 비즈니스 로직이 구현되는 부분입니다. 입력 데이터를 사용자가 정의한 방식으로 `(k2, v2)` 형식으로 변환합니다.
예시를 워드 카운트로 들어보면, `(0, "Hello world") → ("Hello", 1), ("world", 1)` 가 됩니다.

<br>
**🔹 Combiner *(선택 사항)*: `(k2, list(v2)) → (k2, v2')`**
로컬에서 중복된 key를 먼저 합쳐 **Shuffle 트래픽을 줄이는 역할**을 합니다. 작은 로컬 reduce 역할을 하며, 결과 정확성에 영향을 주지 않는 경우에만 사용됩니다.
예시를 들어보면, `("word", [1,1,1]) → ("word", 3)` 이라고 할 수 있습니다.

<br>
**🔹 Partitioner: `(k2, v2') → #Reducer`**
각 key를 어떤 Reducer에 보낼지 결정합니다. 기본은 `hash(k2) % numReducers` 방식이며, 사용자 정의도 가능합니다. 동일한 key는 항상 같은 Reducer로 가야 하므로 **정합성에 중요**합니다.

<br>
**🔹 Shuffle/Sort**
각 Mapper의 출력 데이터를 네트워크를 통해 Reducer로 전송합니다. 이 과정에서 key별로 데이터를 정렬(Sort)하고, 같은 key를 하나로 병합(Merge)합니다.
**MapReduce 전체에서 가장 많은 트래픽이 발생하는 구간**입니다.

<br>
**🔹 Reducer: `(k2, list(v2')) → (k3, v3)`**
정렬되고 그룹화된 데이터를 입력받아 최종 결과를 생성합니다. 사용자가 정의한 `reduce()` 함수가 실행됩니다.
예시를 들어보면, 다음과 같이 됩니다.`("Hello", [1,1,1]) → ("Hello", 3)`

<br>
**🔹 Output: `TextOutputFormat`**
최종 결과를 `(k3, v3)` 형식으로 출력 파일에 저장합니다. 보통 HDFS에 텍스트 파일 형태로 저장됩니다.

<br>
> 🔸 **Combiner와 Partitioner**는 성능 최적화에 큰 역할을 하며, 네트워크 병목을 줄이는 데 매우 중요합니다.

<br>
### 🐘 1.2.7. Combiner 와 Reducer 의 차이


### 🐘 1.2.8. Cascading


<br>
## 🐘 1.3. Map Reduce 2.0 변동사항
---

## 🐘 1.4. Map Reduce 기능과 프로그래밍 실습
---

## 🐘 1.5. Map Reduce 의 한계
---


<br>
<br>
<div align="center">◈</div>
<br>

# ✏️ 결론

<br>
<br>
<div align="center">◈</div>
<br>

# 📚 공부 참고 자료
---

https://westlife0615.tistory.com/m/675