---
title: "📘 Map Reduce 기본 이론과 실습"
tags:
    - Apache
    - Hadoop
    - Study
date: "2025-03-30"
thumbnail: "/assets/img/thumbnail/hadoop_basic_6.png"
bookmark: true
---

저번 포스팅에서는, YARN 에 대하여 공부하였습니다.
이번에는 하둡의 핵심 요소 중 하나인 Map Reduce 에 대하여 공부한 내용을 포스팅하겠습니다.

[📘 분산 시스템의 이해와 하둡의 등장 배경](https://jeondaehong.github.io/%F0%9F%93%96%20%EA%B0%9C%EC%9D%B8%20%EA%B3%B5%EB%B6%80/%F0%9F%91%89%20Apache%20Hadoop/1.%20%EB%B6%84%EC%82%B0%20%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%20%EC%9D%B4%ED%95%B4%EC%99%80%20%ED%95%98%EB%91%A1%EC%9D%98%20%EB%93%B1%EC%9E%A5%20%EB%B0%B0%EA%B2%BD.html)
[📘 하둡의 핵심 구성요소와 이론](https://jeondaehong.github.io/%F0%9F%93%96%20%EA%B0%9C%EC%9D%B8%20%EA%B3%B5%EB%B6%80/%F0%9F%91%89%20Apache%20Hadoop/2.%20%ED%95%98%EB%91%A1%EC%9D%98%20%ED%95%B5%EC%8B%AC%20%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C%EC%99%80%20%EC%9D%B4%EB%A1%A0.html)
[📘 YARN(Yet Another Resource Negotiator) 기본 이론](https://jeondaehong.github.io/%F0%9F%93%96%20%EA%B0%9C%EC%9D%B8%20%EA%B3%B5%EB%B6%80/%F0%9F%91%89%20Apache%20Hadoop/3.%20YARN(Yet%20Another%20Resource%20Negotiator)%20%EA%B8%B0%EB%B3%B8%20%EC%9D%B4%EB%A1%A0.html)

<br>
<br>
<div align="center">◈</div>
<br>


# 🐘 1. Map Reduce

MapReduce는 대용량 데이터를 분산 환경에서 효율적으로 처리하기 위한 병렬 처리 프로그래밍 모델입니다.
이 모델은 원래 2004년 구글에서 발표되었으며, Apache Hadoop은 이를 오픈소스 프레임워크로 구현하였습니다.
Hadoop의 MapReduce는 특히 HDFS와 함께 사용되어, 수백 GB에서 수 PB 규모의 데이터를 여러 대의 컴퓨터에 나눠 처리할 수 있도록 설계되었습니다.

MapReduce는 데이터를 Key-Value 형태로 가공하며, 처리 과정은 크게 Map 단계와 Reduce 단계로 나뉩니다.
Map 단계에서는 데이터를 분할하고 병렬로 처리하며, Reduce 단계에서는 그 결과를 수집하고 통합합니다.

이 구조 덕분에 개발자는 `Map`과 `Reduce` 함수만 정의하면 되고, 나머지 작업(Job 분할, Task 배정, 장애 복구 등)은 Hadoop이 자동으로 처리합니다.

또한 Java를 기본으로 하지만, C++, Python 등 다양한 언어도 지원됩니다 (예: Hadoop Streaming 사용 시).
  
따라서 개발자는 인프라 걱정 없이 비즈니스 로직 구현에 집중할 수 있습니다.

<br>
## 🐘 1.1. MapReduce 알고리즘과 구동방식
---
MapReduce는 크게 두 가지 함수로 구성되어 있습니다.

- **📌 Map Function**  
  입력 데이터를 `(key1, value1)` 형태로 받아, 이를 `(key2, value2)` 형태의 중간 결과로 변환합니다.
  
  ***ex : (key1, value1) → (key2, value2)***
  
- **📌 Reduce Function**  
  Map 단계에서 생성된 중간 결과들을 key 기준으로 그룹화한 뒤, 같은 key를 갖는 값들의 리스트를 받아 최종 결과 `(key3, value3)`을 생성합니다.

  ***ex : (key2, List<value2>) → (key3, value3)***
  
이러한 두 단계를 통해 데이터는 **분산 환경에서 병렬로 처리**되며, 최종적으로 집계 및 가공된 결과를 얻게 됩니다.

또한 MapReduce 의 구동 방식은 크게 세 가지입니다.

- **🔹 Local**
  단일 JVM 에서 전체 Job 을 실행하는 방식으로, 테스트 용도 정도로만 쓰이지 실제로는 이러한 방식으로 운영하지 않습니다.

- **🔹 Classic**
  Hadoop 1.0 버전때까지 유지하던 Map Reduce 분산 처리 방식이며, 1개의 Job Tracker 와 여러개의 Task Tracker 를 사용하는 초기 Map Reduce 방식입니다.

- **🔹 YARN**
  Hadoop 2.0 YARN 도움 이후의 Map Reduce 방식입니다. Map Reduce 이외의 워크로드도 수용이 가능한 버전입니다.

이러한 Map Reduce 는, 단순하고 사용이 편리하며, 특정 데이터 모델이나 스키마에 의존적이지 않은 유연성을 가지고 있고, 저장 구조도 독립적입니다. 또한 데이터 복제에 기반한 내구성과 자체 재시도 로직을 통한 내고장성도 확보하고 있으며, 하둡을 활용한 높은 확장성을 가지고 있다는 장점이 있습니다.

그러나, 고정된 단일 데이터 흐름을 가지고 있고, Hive 등이 있지만 여전히 DBMS 보다는 불편한 스키마 질의, 그리고 작업 데이터를 처리하기에 적합하지 않고, 기술 지원이 어렵다는 단점등을 가지고 있습니다.

그럼 지금부터, MapReduce 에 대해 좀 더 자세히 공부한 내용을 정리해보겠습니다.

<br>
## 🐘 1.2. Map Reduce 1.0
---
과거 Hadoop 1.x 버전에서는 Map Reduce 1.0 버전을 사용하였습니다.

현재는 YARN 을 활용한 Map Reduce 2.0 을 사용하지만, 왜 2.0으로 변화하게 되었는지, 1.0은 어떻게 동작하였는지 그 히스토리를 가볍게 공부하고 정리해보았습니다.

### 🐘 1.2.1. Hadoop 1.x에서의 MapReduce 구성 요소

Hadoop 1.x에서는 클래식 MapReduce 모델을 사용하며, 다음과 같은 주요 컴포넌트로 구성됩니다.

  1. **JobTracker (1개):**
     클러스터 전체에서 Job의 실행을 총괄하는 마스터 역할을 합니다.
     클라이언트로부터 Job을 받아 Task로 나누고, 적절한 TaskTracker에게 분배합니다.

  2. **TaskTracker (여러 개):**
     각각의 노드에 존재하며, JobTracker로부터 Task를 할당받아 실제로 Map 또는 Reduce 작업을 수행합니다.

  3. **Client:**
     사용자가 직접 작성한 MapReduce Job을 hadoop jar 명령어로 실행하면, 이 Job을 제출하는 주체가 됩니다.

  4. **HDFS:**
     Job 실행 중 사용되는 입력 파일, 중간 파일, 출력 파일 등은 모두 HDFS 상에 저장됩니다.
     Mapper/Reducer 간의 데이터 공유도 HDFS를 통해 수행됩니다.

<br>
### 🐘 1.2.2. MapReduce는 언제 동작하는가?

MapReduce는 단순한 파일 업로드, 다운로드, 삭제와 같은 명령어에서는 동작하지 않습니다.
즉, `hdfs dfs -put`, `-get`, `-ls`, `-rm` 같은 명령어를 사용할 때는 **MapReduce**가 관여하지 않으며,
이 경우 HDFS 클라이언트가 직접 NameNode와 DataNode에 요청을 보내 처리합니다.

반면, 다음과 같은 경우에는 MapReduce 엔진이 실제로 Job을 실행합니다.

- hadoop jar로 실행한 MapReduce 프로그램

- Hive, Pig, Oozie 등에서 MapReduce 백엔드를 사용하는 쿼리 실행

- Sqoop import/export 작업

- 기타 사용자 정의 분석 Job

이처럼 MapReduce는 “분산 처리 Job”이 필요한 경우에만 실행됩니다.

<br>
## 🐘 1.3. Map Reduce 2.0
---

## 🐘 1.4. Map Reduce 기능과 프로그래밍 실습
---

## 🐘 1.5. Map Reduce 의 한계
---

## 🐘 1.6. Cascading
---

<br>
<br>
<div align="center">◈</div>
<br>

# ✏️ 결론

<br>
<br>
<div align="center">◈</div>
<br>

# 📚 공부 참고 자료