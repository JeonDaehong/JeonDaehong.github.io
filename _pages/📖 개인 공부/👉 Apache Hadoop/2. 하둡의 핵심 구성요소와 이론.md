---
title: "[#2] 📘 하둡의 핵심 구성요소와 이론"
tags:
    - Apache
    - Hadoop
    - Study
date: "2025-02-15"
thumbnail: "/assets/img/thumbnail/hadoop_basic_2.png"
bookmark: true
---

저번 포스팅에서는, 하둡이 어떻게 등장했는지를 공부하고 정리해봤습니다.

[📘 분산 시스템의 이해와 하둡의 등장 배경](https://jeondaehong.github.io/%F0%9F%93%96%20%EA%B0%9C%EC%9D%B8%20%EA%B3%B5%EB%B6%80/%F0%9F%91%89%20Apache%20Hadoop/1.%20%EB%B6%84%EC%82%B0%20%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%20%EC%9D%B4%ED%95%B4%EC%99%80%20%ED%95%98%EB%91%A1%EC%9D%98%20%EB%93%B1%EC%9E%A5%20%EB%B0%B0%EA%B2%BD.html)

<br>
<div align="center">◈</div>
<br>


# 🐘 1. HDFS

HDFS 는 `Hadoop` 의 ***핵심 아키텍처 중 하나***입니다.
HDFS 의 아키텍처에도 따로 **Block File System, NameNode, DataNode** 등이 있습니다.
HDFS 가 무엇인지를 본격적으로 알아보기 전에, **HDFS** 가 어떤 ***철학과 목표***를 가지고 만들어졌는지, 그 특징은 무엇인지를 간단하게 공부하고 넘어가겠습니다.

<span style="text-decoration: underline; text-decoration-color: red;">**① HDFS 는 하드웨어 장애에 대처할 수 있어야 합니다.**</span>
HDFS를 구성하는 분산 서버에는 다양한 장애가 발생할 수 있습니다.
예를 들면 하드디스크에 오류가 생겨서 데이터 저장에 실패하는 경우, 디스크 복구가 불가능해 데이터가 유실되는 경우, 네트워크 장애가 생겨 특정 분산 서버에 네트워크 접근이 안되는 경우 등이 있을 수 있습니다.
HDFS는 이런 장애를 빠른 시간에 감지하고 대처할 수 있게 설계되어 있습니다.
HDFS에 데이터를 저장하면, 복제본도 함께 저장되어 데이터 유실을 방지하며, 분산 서버 사이에는 주기적으로 health check 를 통해 빠른 시간에 장애를 감지하고 대처할 수 있게 됩니다.


<span style="text-decoration: underline; text-decoration-color: red;">**② HDFS 는 Streaming 식 데이터 접근에 최적화 되어있습니다.**</span>
HDFS는 사용자 요청을 빠르게 처리하는 것보다 동일 시간 내에 더 많은 데이터를 안정적으로 처리하는 데 중점을 둡니다.
따라서 중간부터 읽고, 쓰는 Random Access 방식보다는 처음부터 순차적으로 읽어가는 Streaming 방식에 최적화되어 있습니다.
가끔 이 Streaming 방식이 카프카처럼 실시한 데이터 스트리밍과 헷갈릴 수 있는데, 그런 스트리밍을 의미하는것이 아니라, 처음부터 끝까지 순차적으로 데이터를 읽는데에 특화되었다는 의미입니다.
이런 방식으로 인해 사용자와 상호작용이 많은 트랜잭션 기반 서비스(예: 인터넷 뱅킹, 쇼핑몰 등)보다는 대규모 데이터를 일괄 처리하는 배치 처리(batch processing)에 더 적합합니다.

<span style="text-decoration: underline; text-decoration-color: red;">**③ HDFS 는 대용량 데이터셋 처리에 유리합니다.**</span>
HDFS는 하나의 파일이 수 기가바이트(GB)에서 수 테라바이트(TB)에 이르는 크기로 저장될 수 있도록 설계되어 있습니다.
이를 통해 높은 **데이터 전송 대역폭(bandwidth)**을 지원하며, 수백 대의 노드로 구성된 클러스터를 효율적으로 운영할 수 있습니다. HDFS는 단일 인스턴스에서 수천만 개 이상의 파일을 관리할 수 있습니다.
여기서 말하는 데이터 전송 대역폭은, 한 번에 얼마나 많은 데이터를 빠르게 보낼 수 있는가를 의미합니다.

<span style="text-decoration: underline; text-decoration-color: red;">**④ HDFS 는 심플하고, 일관성이 있습니다.**</span>
데이터 무결성을 유지하기 위해, HDFS는 한 번 저장한 데이터는 수정하지 않고 읽기만 가능한 모델을 따릅니다. 이를 write-once-read-many 모델이라 하며, 데이터가 저장된 후 변경되지 않음으로써 무결성을 보장합니다.
기존에는 저장 후 수정이 전혀 불가능했으나, 현재는 파일의 끝부분에 데이터를 ***append*** 하는 방식은 지원됩니다.
이러한 단순한 일관성 모델은 데이터 처리량을 높이며, 특히 `MapReduce`와 같은 처리 방식에 큰 장점을 제공합니다.

<span style="text-decoration: underline; text-decoration-color: red;">**⑤ HDFS 는 데이터를 직접 옮기지 않고, 데이터가 위치한 노드에서 연산을 실행합니다.**</span>
컴퓨팅 처리를 위해 데이터를 이동시키는 것보다, 연산 작업을 데이터가 위치한 곳으로 이동시키는 것이 비용과 성능 면에서 더 유리합니다. 이는 특히 데이터 양이 방대할수록 더욱 중요합니다. 네트워크 혼잡을 줄이고 시스템 전체의 처리량을 높일 수 있기 때문입니다.
HDFS는 이를 고려하여, 데이터가 위치한 노드에서 연산이 실행되도록 처리합니다. 이러한 접근 방식은 **전체 클러스터의 효율성**을 높이는 데 크게 기여합니다.

<span style="text-decoration: underline; text-decoration-color: red;">**⑥ HDFS 는 여러 플랫폼 간의 이식성을 가지고 있습니다.**</span>
HDFS는 다양한 하드웨어 및 운영체제 환경에서 동일한 기능을 제공할 수 있도록 설계되어 있습니다. 인텔이나 AMD 칩이 설치된 서버에서도 문제없이 동작하며, CentOS나 Red Hat Linux와 같은 다양한 리눅스 배포판에서도 동일하게 사용할 수 있습니다.
이는 HDFS의 서버 코드가 Java 언어로 구현되어 있기 때문에 가능한 일입니다. Java의 플랫폼 독립성이 HDFS의 높은 이식성과 호환성을 보장해 줍니다. 이러한 특성은 HDFS가 대용량 데이터 저장 플랫폼으로 널리 채택되는 중요한 이유 중 하나입니다.

## 🐘 1.1. Block File System
---
HDFS는 블록 구조로 동작하는 분산 파일 시스템입니다.
HDFS에 저장되는 모든 파일은 일정 크기의 블록 단위로 분할되어 여러 서버에 분산 저장됩니다.
기본 블록 크기는 128MB이며, 설정을 통해 조정이 가능합니다. ( 하둡 V1 에서는 64MB였습니다. )
이러한 블록 기반 구조 덕분에 로컬 디스크의 제한을 넘어서 페타바이트(PB) 단위의 대용량 데이터 저장이 가능하게 됩니다.

`hdfs-site.xml` 에서 직접 변경은 가능하지만, 추천을 하지는 않습니다.
```xml
<property>
  <name>dfs.blocksize</name>
  <value>134217728</value> <!-- 128MB -->
</property>
```

### ✅ HDFS에서 파일과 블록은 다음과 같은 규칙을 따릅니다

| 구분                     | 설명                                                                 | 예시                                                                                 |
|------------------------|----------------------------------------------------------------------|-------------------------------------------------------------------------------------|
| 파일과 블록 관계            | 하나의 파일은 하나 또는 여러 개의 블록에 저장됩니다.                                  | 파일 A → 블록 1개 또는 여러 개로 분할 저장                                                      |
| 블록 관리                 | 어떤 파일이 어떤 블록에 저장되는지는 Namenode가 메모리 내 메타데이터로 관리합니다.           | -                                                                                   |
| 블록 독립성               | 하나의 블록에는 여러 파일이 저장되지 않으며, **항상 단일 파일 전용**입니다.                  | 블록 B에는 오직 파일 A 일부만 저장 가능                                                       |
| 블록 분할                | 파일 크기가 블록 크기를 초과하면, 파일은 여러 블록에 나뉘어 저장됩니다.                      | 파일 크기: 128MB + 10byte → 블록 1: 128MB, 블록 2: 10byte                                |
| 블록 크기 미만의 파일        | 파일 크기가 블록보다 작아도 전체 블록을 할당받지만, **사용된 용량만 실제 디스크에 저장**됩니다.     | 파일 크기: 1MB, 블록 크기: 128MB → 블록은 1MB만 사용                                          |
| 블록이 나눠떨어지지 않는 경우 | 파일이 블록 크기로 나눠떨어지지 않으면, 마지막 블록은 남은 크기만큼 점유합니다.                | 파일 크기: 129MB, 블록 크기: 128MB → 블록 1: 128MB, 블록 2: 1MB                             |
| 디스크 점유 공간            | 실제 디스크에서 점유하는 공간은 블록 전체가 아닌, **파일의 실제 크기**만큼입니다.              | 블록 크기: 128MB, 파일 크기: 1MB → 디스크 사용: 1MB                                           |

<br>
### ✅ 이렇게 Block System 을 유지하므로써 다음과 같은 장점을 가질 수 있게 되었습니다.

<span style="text-decoration: underline; text-decoration-color: red;">**① Seek Time 감소**</span>
HDFS는 블록 크기를 고정하여 디스크 탐색 시간을 줄일 수 있습니다. 디스크 탐색 시간은 데이터 위치를 찾는 탐색 시간(seek time)과 해당 위치로 디스크 헤드를 이동시키는 검색 시간(search time)의 합입니다. 하둡이 처음 개발될 당시 일반적인 하드디스크의 평균 탐색 시간은 약 10ms였고, 디스크 I/O 대역폭은 100MB/s였습니다. HDFS는 탐색 시간이 전체 처리 시간의 1%를 넘지 않도록 하는 것을 목표로 했으며, 이를 위해 100MB를 넘지 않고 2의 제곱수에 가까운 `64MB`를 블록 크기로 선택했습니다.

그러나, 큰 파일을 처리하기 위한 효율성과 그 동안 하드웨어 및 네트워크의 성능도 향상되는 과정을 통하여 V2 에서는 `128MB` 로 변경 되었습니다. ( + 클러스터의 효율성 때문이기도 합니다. -> 메타데이터 관리가 더 수월해짐. )

<span style="text-decoration: underline; text-decoration-color: red;">**② 메타데이터 크기 감소**</span>
Namenode는 블록 위치, 파일 이름, 디렉토리 구조, 권한 정보 등의 메타데이터를 메모리에 상주시키고 관리합니다. 블록 크기를 크게 설정하면 하나의 파일을 저장하는 데 필요한 블록 수가 줄어들며, 이에 따라 관리해야 할 메타데이터의 양도 줄어듭니다. 예를 들어 블록 크기가 128MB인 경우, 200MB 파일은 두 개의 블록으로 나뉘며, Namenode는 해당 블록에 대한 정보만 관리하면 됩니다.

반면 일반적인 파일 시스템은 4KB 또는 8KB 크기의 블록을 사용하기 때문에, 동일한 크기의 파일을 저장하려면 수만 개의 블록과 그에 대한 메타데이터가 필요합니다.

예를 들어 블록 크기가 4KB인 경우, 200MB 파일은 약 5만 개의 블록으로 나뉘고, 5만 개의 메타데이터 항목을 Namenode가 관리해야 합니다. Namenode는 단일 서버에서 메타데이터를 처리하므로, 메타데이터가 많아질 경우 성능 저하 및 안정성 문제로 이어질 수 있습니다. 일반적으로 Namenode는 100만 개의 블록을 저장할 때 약 1GB의 힙 메모리를 사용합니다.

<span style="text-decoration: underline; text-decoration-color: red;">**③ 클라이언트와 Namenode 간 네트워크 통신 비용 감소**</span>
클라이언트가 HDFS에 저장된 파일에 접근할 때는 먼저 Namenode에 해당 파일을 구성하는 블록의 위치를 조회합니다. 이때 블록 크기가 작아 블록 수가 많으면, 조회해야 할 메타데이터가 많아지거나 조회 횟수가 증가하게 됩니다.

하지만 블록 크기를 크게 설정하면 파일당 블록 수가 줄어들어 조회에 필요한 정보가 간소화되고, 통신 횟수도 줄어듭니다. 클라이언트는 데이터를 스트리밍 방식으로 처리하기 때문에, 초기 조회 이후에는 특별한 경우가 아니면 Namenode와의 추가적인 통신 없이 작업을 이어나갈 수 있습니다. 이로 인해 전체적인 통신 비용이 줄어듭니다.

<br>
## 🐘 1.2. NameNode 와 DataNode
---

<img src="/assets/img/hdfs_architect.png" alt="HDFS Architecture" />

> 출처 : [HDFS 아키텍처](https://www.cloudduggu.com/hadoop/hdfs/)

### ✅ NameNode
***NameNode***는 HDFS의 핵심 구성요소로서, 블록의 위치, 권한 등과 같은 메타데이터를 관리하는 역할을 합니다. 모든 메타데이터는 기본적으로 **메모리**에 유지되며, 영속성을 위해 다음의 두 가지 파일 형태로도 **디스크**에 기록됩니다.

하나는 **File System Image** 입니다.
NameNode가 처음 시작된 이후부터의 HDFS 네임스페이스 전체 정보를 포함합니다.
디렉터리 구조, 파일명, 파일크기, 생성시간, 수정시간, 블록 매핑 정보, 접근 제어 정보, 복제 수, 파일 상태 등을 포함하고 있습니다.

다른 하나는, **Edit Log** 입니다.
NameNode가 처음 시작된 이후부터 발생한 모든 변경사항을 기록한 로그 파일입니다.

하둡의 NameNode 는 시작된 이후의 네임스페이스 정보를 File System Image 에 기록하고, 그 정보를 메모리에 올림으로써 빠르게 조회 할 수 있도록 합니다. 그리고 변경된 사항들은 전부 Edit Log 에 저장합니다. 이후 NameNode 를 내렸다가 올리게 되면, `Secondary NameNode` 에 의해서 디스크에 있는 Edit Log 와 File System Image 가 병합을 하며 새로운 File System Image 가 만들어지게 됩니다. 그리고 그걸 다시 메모리에 올림으로써, 최신 정보를 유지하고 빠르게 조회 할 수 있도록 합니다.

이러한 **NameNode** 의 역할은 크게 다섯 가지가 있습니다.
<span style="text-decoration: underline; text-decoration-color: red;">**① 메타데이터 관리**</span>
파일 시스템을 구성하는 메타데이터를 관리합니다. 메타데이터는 파일 이름, 디렉토리 구조, 파일 크기, 접근 제어 정보(access/auth control) 및 파일과 블록 간의 매핑 정보를 포함합니다. 클라이언트 요청에 신속하게 응답하기 위해 메타데이터는 메모리 상에서 유지되며, 위에서 이야기한 것처럼 디스크에 기록하기도 합니다.

<span style="text-decoration: underline; text-decoration-color: red;">**② 데이터노드 관리**</span>
클러스터 내의 모든 DataNode 리스트를 유지하고 관리합니다. 관리자에 의한 명시적인 명령 또는 모니터링 결과에 따라 DataNode 상태 정보를 업데이트하거나 변경합니다.

<span style="text-decoration: underline; text-decoration-color: red;">**③ 데이터노드 모니터링**</span>
각 DataNode는 3초마다 NameNode에 heartbeat를 전송합니다. heartbeat에는 데이터노드 상태 정보와 **데이터노드에 저장된 블록 목록(block report)**이 포함됩니다. NameNode는 heartbeat 정보를 바탕으로 DataNode의 가용성, 디스크 용량 상태 등을 판단합니다. 일정 시간 동안 heartbeat를 수신하지 못한 DataNode는 장애가 발생한 노드로 간주됩니다.

<span style="text-decoration: underline; text-decoration-color: red;">**④ 블록 관리**</span>
NameNode는 각 블록의 위치, 복제 상태, 소유 관계 등을 관리합니다. 장애가 발생한 DataNode가 발견되면, 해당 노드에 있던 블록을 다른 정상 노드로 복제합니다. 디스크 용량이 부족한 노드가 있을 경우, 블록을 용량이 여유 있는 노드로 이동시킵니다. 블록의 복제본 수를 유지하여, 기준 복제 수보다 부족하거나 많은 경우 적절히 추가 복제 또는 삭제 작업을 수행합니다.

<span style="text-decoration: underline; text-decoration-color: red;">**⑤ 클라이언트 요청 처리**</span>
클라이언트가 HDFS에 접근할 때는 반드시 NameNode를 통해 먼저 접속합니다. 파일을 저장할 경우, 파일 존재 여부 확인, 저장 권한 검사 등을 수행합니다. 파일을 조회할 경우, 블록이 저장된 DataNode의 위치 정보를 반환합니다.


### ✅ DataNode
DataNode 는 클라이언트가 HDFS에 저장하는 파일을 디스크에 유지하는 Node 입니다.
저장하는 파일은 크게 두 종류인데, 하나는 ***실제 데이터(Raw Data)*** 다른 하나는, checksum 이나 created time 등 ***메타데이터가 설정된 파일***입니다.

이러한 DataNode 는 다음과 같은 기능을 합니다.
<span style="text-decoration: underline; text-decoration-color: red;">**① 실제 데이터 처리**</span>
클라이언트로 부터 실제 데이터의 read/write 요청을 받아 처리합니다.

<span style="text-decoration: underline; text-decoration-color: red;">**② block 생성,복제,삭제**</span>
NameNode 로부터 명령을 받아서, 자신의 디스크에 있는 block 을 생성, 복제, 삭제를 수행합니다.

<span style="text-decoration: underline; text-decoration-color: red;">**③ heartbeat 전송**</span>
HDFS 의 상태를 NameNode 에게 heartbeat 로 전송합니다.

<span style="text-decoration: underline; text-decoration-color: red;">**④ block 정보 전송**</span>
NameNode에게 자신이 가진 데이터 block 들의 리스트와 상태를 전송합니다.


## 🐘 1.3. Secondary NameNode
---

<img src="/assets/img/secondaryNamenode.png" alt="secondaryNamenode" />

> 출처 : [Secondary Namenode](https://westlife0615.tistory.com/629#:~:text=%EA%B0%80%20%EB%A7%8C%EB%93%A4%EC%96%B4%EC%A7%91%EB%8B%88%EB%8B%A4.-,Secondary%20NameNode%20%EB%9E%80%20%3F,%EA%B4%80%EB%A0%A8%EB%90%9C%20%EA%B8%B0%EB%8A%A5%EC%9D%84%20%EC%A0%9C%EA%B3%B5%ED%95%A9%EB%8B%88%EB%8B%A4.)



## 🐘 1.4. Replication
---


## 🐘 1.5. Read 와 Write 시 내부에서 벌어지는 일
---


<br>
<br>
<div align="center">◈</div>
<br>

# 🐘 2. Hadoop H/A 클러스터

## 🐘 2.1. 클러스터 구성 위해 잠시 짚어갈 Zookeeper
---


## 🐘 2.2. Quorum Journal Nodes H/A
---


## 🐘 2.3. Shared Storage H/A
---


## 🐘 2.4. Automatic Failover
---


## 🐘 2.5. Observer Name Node ( ONN )
---

<br>
<br>
<div align="center">◈</div>
<br>

# 🐘 3. Eraser Coding

## 🐘 3.1. Software Eraser Coding
---

## 🐘 3.2. Hardware Eraser Coding
---

## 🐘 3.3. 하둡에서의 Eraser Coding
---

<br>
<br>
<div align="center">◈</div>
<br>

# 🐘 4. YARN

## 🐘 4.1. YARN 이란
---

## 🐘 4.2. YARN 아키텍처
---

### 🐘 4.2.1. 기본 아키텍처

### 🐘 4.2.2. Resource Mananger

### 🐘 4.2.3. Node Manager


## 🐘 4.3. YARN 의 작업 흐름
---

### 🐘 4.3.1. High Level Workflow

### 🐘 4.3.2. Application 실행 요청

### 🐘 4.3.3. Application Master 실행 요청

### 🐘 4.3.4. Application Master 등록

### 🐘 4.3.5. 컨테이너 실행

### 🐘 4.3.6. Application Master 종료

### 🐘 4.3.7. Auxiliary Service


## 🐘 4.4. Fair Call Queue 와 FIFO Queue
---

## 🐘 4.5. YARN 실습
---

<br>
<br>
<div align="center">◈</div>
<br>

# 🐘 5. Map Reduce

## 🐘 5.1. Map Reduce 란
---

## 🐘 5.2. Map Reduce 기능과 프로그래밍
---

## 🐘 5.3. Map Reduce 실습
---

## 🐘 5.4. Map Reduce 의 한계
---

## 🐘 5.5. Cascading
---

<br>
<br>
<div align="center">◈</div>
<br>

# ✏️ 결론

<br>
<br>
<div align="center">◈</div>
<br>

# 📚 공부 참고 자료