---
layout: post
title:  "[#4] 견고한 데이터 엔지니어링 공부 (1)"
author: daehong
categories: [ study, data-engineering ]
image: assets/images/robust-data-engineering.jpg
featured: true
rating: 5
---

이 책은 데이터 엔지니어의 역할을 단순히 기업 의사결정을 지원하는 것을 넘어, 데이터의 생성부터 저장, 수집, 변환, 서빙에 이르는 데이터 생명주기 전반에서 ROI를 극대화하고 리스크를 최소화하며 비즈니스에 실질적인 가치를 더하는 데 초점을 맞추고 있습니다.

데이터 관리, 보안, DevOps, 아키텍처, 소프트웨어 엔지니어링 등 다양한 요소를 통합적으로 고려해야 한다는 점에서 데이터 엔지니어를 '데이터 생명주기 엔지니어'로 정의하며, 데이터 엔지니어로서 갖춰야 할 핵심 역량과 본질적인 역할에 대해 깊이 있는 통찰을 제공하고 있습니다.

이 책을 공부함으로써, 데이터 엔지니어링의 기초를 다질 수 있었고, 보다 넓은 시야로 데이터 엔지니어링의 생태계를 볼 수 있는 눈을 얻게 되었습니다.

<br>

## 📚 1장 : 데이터 엔지니어링 기반 구축하기 ️
---

### ✏️ 1-1. 데이터 엔지니어링이란?

- <span style="color:blue;">**🔥 알텍스소프트의 데이터 엔지니어링의 개념, 프로세스 및 도구**</span>

	알텍스소프트에 따르면, 데이터 엔지니어링은 데이터 과학자, 데이터 분석가, 비즈니스 인텔리전스 개발자 등 조직 내 다양한 전문가들이 데이터를 효과적으로 활용할 수 있도록 지원하는 작업의 집합입니다.

	데이터 엔지니어는 대규모 데이터를 수집하고 저장하며, 이를 추가 분석에 적합한 형태로 준비하기 위해 시스템을 설계하고 구축합니다.

	이를 통해 조직의 데이터 인프라를 구축하고 운영하여 데이터 분석과 과학 작업이 원활히 이루어질 수 있도록 돕는 중요한 역할을 합니다.
	

- <span style="color:blue;">**🔥 데이터 엔지니어링 정의**</span>

	데이터 엔지니어링은 원시 데이터를 가져와 분석 및 머신러닝과 같은 다운스트림 사용 사례를 지원하기 위해 고품질의 일관된 정보를 제공하는 시스템과 프로세스를 개발, 구현, 유지 관리하는 작업입니다.
	
	이는 보안, 데이터 관리, 데이터 운영, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링의 교차점에서 이루어집니다.
	
	데이터 엔지니어는 데이터 엔지니어링의 수명 주기를 관리하며, 원천 시스템에서 데이터를 가져오는 것부터 시작해 이를 분석 및 머신러닝과 같은 사용 사례에 활용할 수 있도록 준비하는 과정을 책임집니다.
	
	
- <span style="color:blue;">**🔥 데이터 엔지니어링 생명(수명) 주기**</span>

	데이터 생성(generation) ➜ 데이터 저장(Storage) ➜ 데이터 수집(Ingestion) ➜ 데이터 변환(Transformation) ➜ 데이터 서빙(Serving)
	
	데이터 엔지니어링 수명 주기는 전체 수명 주기에 걸쳐 중요한 아이디어인 드러나지 않는 요소(undercurrent)라는 개념을 포함합니다.
	
	여기에는 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링이 포함됩니다.
	
	
- <span style="color:blue;">**🔥 데이터 엔지니어의 진화**</span>

	데이터 엔지니어링의 역사는 1980년대 데이터 웨어하우스 개념의 형성으로 시작되었습니다. 이 시기에는 IBM의 관계형 데이터베이스와 SQL의 개발, 그리고 오라클에 의한 대중화가 이뤄졌으며, 빌 인먼과 랄프 킴벌은 데이터 모델링 기법과 접근 방식을 발전시켰습니다. 데이터 웨어하우스는 대량의 데이터를 처리하고 확장성 있는 분석 환경을 제공하기 위해 다중 병렬 처리(MPP) 데이터베이스를 도입하며 BI 엔지니어와 ETL 개발자 같은 역할의 중요성을 부각시켰습니다.

	1990년대 중반 인터넷이 주류로 자리 잡으면서 AOL, 야후, 아마존 같은 웹 우선(web-first) 기업이 등장했고, 닷컴 열풍은 웹 애플리케이션과 이를 지원하는 백엔드 시스템에서 엄청난 활동을 일으켰습니다. 당시 대부분의 인프라는 비용이 많이 들고 비효율적이었지만, 데이터와 시스템의 중요성이 점점 커졌습니다.

	2000년대 초, 닷컴 버블이 무너진 후 생존한 기업들(야후, 구글, 아마존 등)은 기존의 전통적인 모놀리식 데이터베이스와 데이터 웨어하우스를 한계까지 밀어붙이며 데이터 처리 문제를 해결하기 위해 혁신을 모색했습니다.
	
	구글은 2003년 구글 파일 시스템 논문과 2004년 맵리듀스 논문을 발표하며 대규모 데이터 처리의 새로운 패러다임을 제시했습니다. 이 논문들은 야후 엔지니어들에 의해 아파치 하둡의 개발로 이어졌고, 기업들은 점차 테라바이트와 페타바이트 규모의 데이터를 다루기 시작했습니다.

	같은 시기, 아마존은 EC2, S3, 다이나모DB 같은 데이터 빌딩 블록을 구축하며 클라우드 컴퓨팅의 가능성을 열었습니다. AWS의 성공은 구글 클라우드, 마이크로소프트 애저 등 퍼블릭 클라우드의 등장을 촉진하며 데이터 애플리케이션 개발과 배포 방식을 혁신했습니다.

	2000년대와 2010년대에는 하둡 생태계를 중심으로 한 오픈 소스 빅데이터 도구들이 급격히 성숙했습니다. 하둡, 스파크, 하이브, 카산드라 같은 기술이 발전하며 데이터 엔지니어링은 배치 처리에서 이벤트 스트리밍으로 전환되었고, 실시간 빅데이터 시대가 열렸습니다. 이 시기의 빅데이터 엔지니어는 대규모 클러스터를 유지 관리하고, 코드 우선(code-first) 방식으로 데이터 처리를 최적화하며 기존의 GUI 중심 도구를 대체했습니다.

	2020년대에 들어 데이터 엔지니어링은 또 한 번의 변화를 겪고 있습니다. 기존의 하둡이나 인포매티카 같은 모놀리식 프레임워크에서 벗어나 점점 더 분산되고 모듈화된, 고도로 추상화된 도구들이 주류가 되고 있습니다. 데이터 엔지니어는 다양한 기술을 연결하고 상호 운용하며 비즈니스 목표를 지원하는 데 초점을 맞추고 있습니다.

	이제 데이터 엔지니어는 단순히 데이터를 처리하고 제공하는 역할을 넘어 데이터 수명 주기 전반을 관리하며, 보안, 개인정보 보호, 규정 준수 같은 가치 사슬의 상위 영역에 집중하고 있습니다. CCPA, GDPR 같은 데이터 규정을 숙지하고, 파이프라인 설계 시 개인정보 보호와 익명화, 데이터 품질 및 규정 준수를 고려하는 등 데이터 엔지니어링의 역할은 기술적 과제와 비즈니스 요구를 동시에 해결하는 방향으로 진화하고 있습니다.
	
<br>
	
### ✏️ 1-2. 데이터 엔지니어링 기술과 활동

데이터 엔지니어링은 단순히 데이터를 처리하는 기술적인 측면만을 포함하는 것이 아니라, 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처 및 소프트웨어 엔지니어링과 같은 여러 핵심 요소들이 숨어 있는 복잡한 작업입니다.

데이터 엔지니어는 이러한 다양한 복잡한 가변적인 요소를 처리하며, 비용, 민첩성, 확장성, 단순성, 재사용성, 상호 운용성 등을 고려하여 지속적으로 시스템을 최적화해야 합니다.

- <span style="color:blue;">**🔥 데이터 성숙도와 데이터 엔지니어**</span>

	데이터 성숙도는 조직이 더 높은 데이터 활용률, 기능, 통합을 달성하려는 과정입니다.
	
	데이터 성숙도가 높아질수록 조직은 데이터를 보다 효과적으로 활용할 수 있고, 이를 통해 비즈니스 경쟁력을 강화할 수 있습니다. 데이터 성숙도를 위한 단계는 기업마다 다르지만, 일반적으로 단순화된 기업용 데이터 성숙도 모델을 따르게 됩니다.

	**데이터로 시작하기 단계**에서는, 데이터 엔지니어는 기업의 목표를 지원하는 데이터 아키텍처를 설계하고 구축하는 데 중요한 역할을 합니다. 또한, 데이터를 다루는 이니셔티브를 통해 달성하려는 경영 목표와 경쟁 우위를 결정하고, 이를 지원하는 데이터 아키텍처를 구축하는 것이 필수적입니다. 이 과정에서 데이터 아키텍트가 없을 경우, 데이터 엔지니어가 홀로 진행할 수 있습니다.

	**데이터로 확장하기 단계**에서는 데이터 엔지니어는 조직 내에서 공식적인 데이터 관행을 수립하고, 확장 가능하고 견고한 데이터 아키텍처를 구축하며, 데브옵스 및 데이터옵스 관행을 채택해야 합니다. 또한, 머신러닝(ML)을 지원하는 시스템을 구축하고, 경쟁 우위를 확보할 수 있는 부분에 대해서만 커스터마이징을 수행합니다.

	**데이터로 선도하기 단계**에서는 이전 단계를 계속해서 확장하며, 새로운 데이터의 매끄러운 배포와 사용을 위한 자동화를 구축합니다. 또한, 데이터를 경쟁 우위로 활용하기 위한 사용자 정의 도구와 시스템을 구축하는 데 집중하고, 데이터 관리 및 데이터옵스와 같은 기업 차원의 데이터 측면에 집중합니다. 이때 데이터 카탈로그, 데이터 계보 도구, 메타데이터 관리 시스템을 포함하여 데이터를 조직 전체에 효율적으로 노출하고 전파하는 도구를 배포합니다. 또한, 소프트웨어 엔지니어, ML 엔지니어, 분석가 등과 협력하며, 협업과 공개적인 토론이 가능한 커뮤니티와 환경을 조성하는 것이 중요합니다.


- <span style="color:blue;">**🔥 데이터 엔지니어의 배경과 기술**</span>

	데이터 엔지니어는 데이터와 기술을 모두 이해해야 하며, 데이터 관리의 모범 사례와 더불어 도구의 다양한 옵션, 상호작용, 상충 관계를 숙지해야 합니다.
	
	이를 위해 소프트웨어 엔지니어링, 데이터옵스, 데이터 아키텍처에 대한 이해가 필수적입니다.
	

- <span style="color:blue;">**🔥 기술 책임과 데이터 엔지니어링의 주요 언어**</span>

	최근 들어 완전 관리형 서비스가 등장하면서 데이터 엔지니어들은 과거의 복잡한 저수준 프로그래밍 작업에서 벗어나, 고수준의 추상화 작업이나 오케스트레이션 프레임워크 내에서 파이프라인을 코드로 작성하는 일에 더 집중하게 되었습니다.

	데이터 엔지니어링에서 사용하는 주요 언어로는 SQL이 있습니다. SQL은 스파크 SQL, 구글 빅쿼리, 스노우플레이크, 하이브와 같은 도구에서 대량의 데이터를 처리하는 데 사용되며, 아파치 플링크, 빔, 카프카와 같은 스트리밍 프레임워크에서도 지원됩니다.

	또한, Python, Java, Scala와 같은 언어도 데이터 엔지니어링에서 중요한 역할을 합니다. 특히 **Java Virtual Machine (JVM)**은 스파크, 하이브, 드루이드와 같은 오픈 소스 프로젝트에서 널리 사용되며, 파이썬보다 성능이 뛰어나고 저수준의 기능에 접근할 수 있는 장점이 있습니다. 따라서 자바와 스칼라를 이해하면 오픈 소스 데이터 프레임워크 활용에 큰 도움이 됩니다.

	이외에도 Bash는 간단한 작업 자동화와 스크립팅에 널리 사용되며, 필요에 따라 R, JavaScript, Go, Rust, C/C++, C#, Julia와 같은 언어도 활용됩니다.
	
	이러한 다양한 언어들은 데이터 엔지니어의 역량을 넓히고, 특정 데이터 처리 및 분석 요구를 충족하는 데 중요한 역할을 합니다.
	
	
	
- <span style="color:blue;">**🔥 A에서 B로 이어지는 데이터 엔지니어링 역할의 연속성**</span>
	
	**"A형 데이터 엔지니어"**
	
	A는 **추상화(Abstraction)**를 의미합니다.
		
	A형 데이터 엔지니어는 데이터 아키텍처를 단순하고 추상적으로 유지하며, 차별화되지 않은 과중한 작업을 피하려 노력합니다.
		
	이들은 기성 제품, 관리형 서비스, 그리고 SaaS 도구를 주로 사용하여 데이터 엔지니어링 수명 주기를 관리합니다.
		
	A형 데이터 엔지니어는 데이터 성숙도와 무관하게 다양한 산업과 회사에서 널리 활동합니다.
	
	**"B형 데이터 엔지니어"**
	
	B는 **구축(Build)**을 의미합니다.
		
	B형 데이터 엔지니어는 기업의 핵심 경쟁력을 확장하고 지원할 수 있는 맞춤형 데이터 도구와 시스템을 설계하고 구축합니다.
		
	이들은 주로 데이터 성숙도의 **2단계(데이터로 확장하기)**와 **3단계(데이터로 선도하기)**에 해당하는 기업이나, 초기 데이터 사용 사례가 독특하고 중요해 맞춤형 도구가 필요한 조직에서 활발히 활동합니다.
	
	**이 두 유형은 서로 상호 보완적인 역할을 하며, 데이터 엔지니어링의 다양한 요구를 충족시키기 위해 긴밀히 협력합니다.**

<br>

### ✏️ 1-3. 조직 내 데이터 엔지니어

- <span style="color:blue;">**🔥 내부 대면 vs 외부 대면 데이터 엔지니어**</span>

	**"1. 외부 대면 데이터 엔지니어"**
	
	외부 대면 데이터 엔지니어는 외부 사용자와 연계되는 애플리케이션을 지원하는 데 초점을 맞춥니다.
	
	이들은 소셜 미디어 앱, 사물 인터넷(IoT) 장치, 전자 상거래 플랫폼과 같은 외부 애플리케이션에서 생성되는 트랜잭션과 이벤트 데이터를 처리합니다.
	
	주요 역할로는 이러한 데이터를 수집, 저장, 처리하기 위한 시스템의 설계, 구축, 그리고 관리를 포함합니다.
	
	**"2. 내부 대면 데이터 엔지니어"**
	
	내부 대면 데이터 엔지니어는 비즈니스 및 내부 이해관계자의 요구를 충족시키는 활동에 집중합니다.
	
	이들은 BI 대시보드와 보고서를 생성하거나, 데이터 과학 및 머신러닝 모델을 위한 데이터 파이프라인과 데이터 웨어하우스를 설계하고 유지 관리합니다.
	
	내부 데이터를 활용하여 조직 내에서 더 나은 의사결정을 지원하는 것이 이들의 주요 목표입니다.
	
	
- <span style="color:blue;">**🔥 데이터 엔지니어와 기타 기술 역할**</span>

	데이터 엔지니어는 소프트웨어 엔지니어, 데이터 아키텍트, 데브옵스 엔지니어 또는 사이트 신뢰성 엔지니어(SRE) 같은 데이터 생산자(data producer)와 데이터 분석가, 데이터 과학자, ML 엔지니어 등과 같은 데이터 소비자(data consumer)사이에서 허브 역할을 합니다.
	
	또한 데이터 엔지니어는 데브옵스 엔지니어와 같이 운영 역할을 하는 사람들과 소통합니다.

	
- <span style="color:blue;">**🔥 데이터 엔지니어와 업스트림 이해관계자**</span>

	**데이터 아키텍트**는 조직의 데이터 관리를 위한 청사진을 설계하고, 데이터 아키텍처 및 프로세스를 매핑합니다. 이들은 사일로를 제거하고 데이터 관리 및 거버넌스 전략을 조율하며, 클라우드 마이그레이션과 신규 설계 프로젝트에서 핵심적인 역할을 합니다.
	
	**소프트웨어 엔지니어**는 비즈니스 운영을 지원하는 애플리케이션과 시스템을 개발합니다. 이 과정에서 생성되는 애플리케이션 이벤트 데이터와 로그는 데이터 엔지니어가 사용하는 중요한 내부 데이터 자산입니다.

	**데브옵스 엔지니어와 SRE(Site Reliability Engineer)**는 시스템 운영과 모니터링을 통해 데이터를 생성하며, 데이터 엔지니어는 이들과 협력해 데이터 파이프라인의 안정성과 효율성을 개선합니다.


- <span style="color:blue;">**🔥 데이터 엔지니어와 다운스트림 이해관계자**</span>

	**데이터 과학자**는 데이터를 분석하여 미래를 예측하고 추천 시스템을 설계합니다. 데이터 엔지니어는 이들이 작업에 필요한 데이터 준비를 돕고, 모델 배포와 확장을 지원하며 데이터 과학 워크플로의 효율성을 높입니다.
	
	**데이터 분석가**는 주로 과거와 현재의 데이터를 분석하여 비즈니스 성과를 파악합니다. 이들은 SQL 쿼리와 BI 도구를 활용하며, 데이터 정의 및 품질 문제에 정통한 도메인 전문가로서 조직의 의사결정 과정에 기여합니다.

	**머신러닝 엔지니어**는 고급 머신러닝 모델을 설계하고 훈련하며, 이를 운영 환경에 배포합니다. 데이터 엔지니어는 이들과 협력하여 ML 워크플로를 지원하고, 클라우드 기반 환경에서 모델의 확장 가능성을 보장합니다.

<br>
<br>

## 📚 2장 : 데이터 엔지니어링 수명 주기
---

### ✏️ 2-1. 데이터 엔지니어링 수명 주기란?

**데이터 엔지니어링 수명 주기** : 원시 데이터의 요소를 분석가, 데이터 과학자, ML 엔지니어 등이 사용할 수 있는 유용한 최종 제품으로 전환하는 단계로 구성됩니다.

- <span style="color:blue;">**🔥 데이터 생성**</span>

	원천 시스템은 데이터 엔지니어링 수명 주기에서 사용되는 데이터의 원본입니다. 예를 들어, IoT 장치, 애플리케이션 메시지 대기열, 트랜잭션 데이터베이스 등이 원천 시스템이 될 수 있습니다. 데이터 엔지니어는 원천 시스템의 작동 방식, 데이터 생성 방식, 빈도, 속도, 그리고 데이터의 다양성을 실무적으로 이해해야 합니다.

	원천 시스템 평가에 있어 주요 엔지니어링 고려 사항은 데이터 원천의 본질적인 특징을 이해하는 것입니다. 원천 시스템이 애플리케이션인지, IoT 장치의 스웜인지 등을 파악해야 합니다. 또한 데이터가 어떻게 유지되는지, 장기간 보존되는지 아니면 일시적으로 삭제되는지 확인해야 합니다. 데이터는 어떤 속도로 생성되며, 초당 몇 개의 이벤트나 시간당 몇 기가바이트가 발생하는지도 중요한 요소입니다.

	데이터 엔지니어는 출력 데이터에서 일관성을 기대할 수 있는 정도를 평가해야 합니다. 데이터 품질 검사에서 예기치 않은 출력값이나 잘못된 데이터 포맷과 같은 불일치 사례가 얼마나 자주 발생하는지도 고려해야 합니다. 또한, 에러 빈도와 데이터의 중복 여부, 데이터 도착 시점에 대한 문제도 평가해야 합니다.

	수집된 데이터의 스키마와 이를 완전히 파악하기 위해 여러 테이블이나 시스템에 걸쳐 조인해야 하는지에 대한 여부도 중요한 평가 요소입니다. 스키마가 변경될 때의 대응 방안과 다운스트림 이해관계자에게 이를 전달할 방법도 고려해야 합니다. 또한, 원천 시스템에서 데이터를 얼마나 자주 가져와야 하는지에 대한 여부와, 상태가 있는 시스템의 경우 데이터가 스냅숏 형태로 제공되는지, 변경 데이터 캡처(CDC)를 통해 갱신 이벤트로 제공되는지 확인해야 합니다.

	원천 시스템의 데이터 조회가 성능에 미치는 영향, 업스트림 시스템의 데이터 의존 관계, 늦거나 누락된 데이터 확인을 위한 데이터 품질 검사 실시 여부도 고려해야 합니다. 스키마리스 방식은 스키마가 없다는 의미가 아니라, 애플리케이션이 메시지 대기열, 플랫 파일, BLOB 또는 도큐먼트 데이터베이스에서 데이터가 기록될 때 스키마를 정의하는 방식입니다. 관계형 데이터베이스에서는 고정 스키마 방식을 사용하며, 애플리케이션은 이를 준수해야 합니다.


- <span style="color:blue;">**🔥 데이터 저장**</span>

	스토리지 시스템 평가에 있어 데이터 웨어하우스, 데이터 레이크하우스, 데이터베이스 또는 객체 스토리지의 선택은 몇 가지 중요한 엔지니어링 질문을 기반으로 진행됩니다. 우선, 해당 스토리지 솔루션이 아키텍처에서 요구하는 쓰기 및 읽기 속도와 잘 맞는지 확인해야 합니다. 또한, 스토리지가 다운스트림 프로세스의 병목 현상을 초래하지 않는지도 점검해야 합니다.

	스토리지 시스템이 어떻게 작동하는지 이해하고, 이를 최적으로 활용하는지 확인하는 것이 중요합니다. 예를 들어, 객체 스토리지 시스템에서 높은 비율의 임의 접근 갱신을 적용하는 것은 성능 오버헤드가 큰 안티패턴이 될 수 있습니다. 또한, 스토리지 시스템이 향후 예상되는 확장을 처리할 수 있는지도 고려해야 합니다. 사용 가능한 총 스토리지, 읽기 작업 속도, 쓰기 볼륨 등 스토리지 시스템의 용량 제한을 점검해야 합니다.

	다운스트림 사용자와 프로세스가 필요한 서비스 수준 협약(SLA)에 따라 데이터를 취득할 수 있는지도 중요한 평가 요소입니다. 또한, 스키마 진화, 데이터 흐름, 데이터 계보 등에 대한 메타데이터를 캡처하고 있는지 확인해야 합니다. 메타데이터는 데이터 활용성에 큰 영향을 미치며, 미래의 프로젝트와 아키텍처 변경을 간소화할 수 있습니다.

	스토리지 시스템이 순수 스토리지 솔루션인지, 아니면 복잡한 쿼리 패턴을 지원하는지 (예: 클라우드 데이터 웨어하우스) 확인하는 것도 필요합니다. 또한, 스토리지 시스템이 스키마에 구애받지 않는지, 유연한 스키마를 제공하는지, 아니면 강제된 스키마가 있는지 점검해야 합니다. 데이터 거버넌스를 위해 마스터 데이터, 골든 레코드 데이터 품질 및 데이터 계보를 어떻게 추적하고 있는지, 그리고 법령 준수 및 데이터 주권을 어떻게 대처하는지도 중요한 요소입니다.

	데이터 접근 빈도에 따라 데이터 온도도 결정됩니다. 핫 데이터는 가장 자주 액세스되는 데이터로, 빠른 검색을 위해 저장되어야 합니다. 미온적 데이터는 가끔 액세스되는 데이터로, 적절한 저장 방식이 필요합니다. 콜드 데이터는 거의 쿼리되지 않으며, 아카이브 시스템에 저장되는 데이터로, 규정 준수나 장애 복구 목적 등으로 보관될 수 있습니다.


- <span style="color:blue;">**🔥 데이터 수집**</span>

	데이터 수집 단계에서 중요한 엔지니어링 고려 사항은 여러 가지가 있습니다. 먼저, 수집 중인 데이터의 사용 사례를 정의해야 합니다. 같은 데이터셋의 여러 버전을 생성하는 대신 데이터를 재사용할 수 있는지 평가해야 합니다. 또한, 시스템이 데이터를 안정적으로 생성하고 수집하는지, 그리고 필요할 때 데이터를 사용할 수 있는지 확인해야 합니다.

	수집 후 데이터의 목적지도 중요한 고려 사항입니다. 데이터가 얼마나 자주 접근되어야 하는지, 도착하는 데이터의 용량, 그리고 데이터 형식은 무엇인지도 파악해야 합니다. 이러한 형식을 다운스트림 스토리지와 변환 시스템이 처리할 수 있는지도 확인해야 합니다. 원천 데이터가 다운스트림에서 즉시 사용할 수 있는 상태인지, 그렇다면 얼마나 오래 사용할 수 있는지, 사용할 수 없게 되는 요인은 무엇인지를 평가해야 합니다.

	데이터가 스트리밍 소스에서 전송되는 경우, 목적지에 도달하기 전에 데이터를 변환해야 하는지 여부도 중요한 질문입니다. 데이터가 스트림 내에서 변환되는 것이 적절한지, 혹은 다른 형태의 변환이 필요한지 고려해야 합니다.

	**"배치 수집과 스트리밍 수집에 대한 고려 사항도 필수적입니다."**
	
	스트리밍 수집은 데이터를 실시간으로 제공할 수 있는 방법으로, 이벤트 스트리밍과 처리 플랫폼의 발전으로 더욱 인기를 얻고 있습니다. 배치 수집은 데이터를 일정한 시간 간격으로 큰 청크로 처리하는 방법으로, 분석 및 머신러닝에 적합합니다.

	배치와 스트리밍 수집의 주요 차이점은 데이터 처리 방식과 실시간 데이터 수집의 필요성 여부입니다. 스트리밍 수집이 배치 수집보다 더 적합한지 여부를 판단하려면, 다운스트림 시스템이 데이터를 실시간으로 처리할 수 있는지, 그리고 실시간 수집의 밀리초 단위로 데이터를 축적하고 수집하는 마이크로 배치 접근이 효과적인지 평가해야 합니다.

	스트리밍 수집을 사용할 때 얻을 수 있는 구체적인 이점과 개선된 데이터 처리 방안도 고려해야 합니다. 또한, 스트리밍 우선 접근 방식이 시간, 비용, 유지 보수, 다운타임 및 기회비용 측면에서 더 많은 비용을 소비할지 여부를 평가해야 합니다.

	데이터 수집 시스템이 안정적이고 다중화되어 있는지, 장애 발생 시 어떻게 대응할 수 있는지도 점검해야 합니다. 수집에 가장 적합한 도구로는 관리형 서비스나, Kafka, Flink, Spark, Pulsar와 같은 인스턴스를 선택할 수 있습니다. 후자의 경우, 관리 역할과 비용, 트레이드오프를 고려해야 합니다.

	**"푸시와 풀 방식은 데이터 수집에서 중요한 두 가지 모델입니다."**
	
	푸시 모델에서는 원천 시스템이 타깃에 데이터를 씁니다. 풀 모델에서는 수집 시스템이 원천 시스템에서 데이터를 검색합니다. ETL 프로세스에서는 일반적으로 풀 모델을 사용하며, 추출 부분은 정해진 일정에 따라 소스 테이블을 쿼리합니다.

	또한, 연속적인 CDC(변경 데이터 캡처) 방식도 고려해야 합니다. 이는 원천 데이터베이스에서 변경된 데이터를 실시간으로 추적하고 메시지를 트리거하여 수집 시스템이 이를 처리하는 방식입니다. 바이너리 로그를 사용하는 CDC 방식은 원천 데이터베이스에 추가적인 부하를 주지 않으면서 데이터를 처리할 수 있습니다.
	
	Kafka 의 컨슈머나, Spark 등에서는 Pull 방식을 이용하며, RabbitMQ 등에서는 Push 방식을 이용합니다.
	
	
- <span style="color:blue;">**🔥 데이터 변환**</span>

	데이터 변환 단계에서 고려해야 할 주요 사항은 다음과 같습니다.

	먼저, 변환에 드는 비용을 평가해야 합니다. 변환이 비즈니스에 미치는 가치를 이해하고, 변환 작업이 제공하는 비즈니스 가치를 명확히 해야 합니다. 이를 통해 변환 작업이 얼마나 중요한지, 그리고 이에 대한 자원을 할당할 만한 가치가 있는지를 판단할 수 있습니다.

	다음으로, 변환이 가능한 한 단순하고 독립적인지 확인해야 합니다. 복잡한 변환 작업은 오류 가능성을 높이고 유지 보수를 어렵게 만들 수 있으므로, 가능한 한 간단하게 구성하는 것이 좋습니다. 독립적인 변환은 시스템이나 다른 작업에 영향을 미치지 않고 개별적으로 수행될 수 있어 유리합니다.

	또한, 변환이 지원하는 비즈니스 규칙은 무엇인지 파악해야 합니다. 데이터 변환은 종종 비즈니스 규칙을 기반으로 하여 데이터를 형식에 맞게 정리하거나 변환하는 작업을 수행하므로, 이러한 규칙을 정확히 이해하고 준수하는 것이 중요합니다.
	
	
- <span style="color:blue;">**🔥 데이터 서빙**</span>

	데이터 서빙은 수집, 저장, 변환 후에 데이터로부터 가치를 창출하는 과정입니다. 이 단계에서는 분석 및 비즈니스 인텔리전스(BI), 운영 분석, 임베디드 분석, 머신 러닝, 역 ETL 등 다양한 영역이 고려됩니다.

	데이터 허영(data vanity) 프로젝트는 기업의 주요 리스크가 될 수 있으며, 많은 기업들이 불필요한 대규모 데이터셋을 수집하여 유용하게 활용되지 않는 데이터 레이크를 만들어 놓는 실수를 범하고 있습니다.

	**분석 단계**에서는 데이터를 저장하고 변환한 후, 보고서 또는 대시보드를 생성하고 임시 분석을 통해 데이터를 활용할 수 있습니다. 비즈니스 인텔리전스(BI)는 기업 경영의 과거와 현재 상태를 설명하기 위해 데이터를 수집하고, 비즈니스 로직을 통해 원시 데이터를 처리합니다. 기업의 데이터 성숙도가 높아짐에 따라, 비즈니스 사용자가 IT 부서의 개입 없이도 셀프서비스 분석을 할 수 있게 됩니다. 그러나 셀프서비스 분석은 데이터 품질 저하, 조직 사일로 현상, 적절한 데이터 기술 부족 등으로 어려움이 있을 수 있습니다. 운영 분석은 재고 물품이나 웹사이트, 애플리케이션 상태 등의 실시간 뷰를 제공하는 대시보드로, 사용자가 즉시 수행할 수 있는 작업을 촉진합니다. 임베디드 분석은 고객에게 분석 결과를 제공할 수 있는 기능으로, 대규모 고객에게 데이터와 분석을 제공할 수 있습니다. 이때 각 고객은 자신의 데이터만 확인할 수 있어야 하며, 데이터 유출과 보안 취약성에 대한 대응이 중요합니다.

	**머신 러닝**에서는 신뢰할 수 있는 특성 엔지니어링과 충분한 품질의 데이터가 필요하며, 데이터가 실제 상황을 잘 반영하고 불공평하게 편향되지 않았는지 확인해야 합니다. 또한, 데이터가 쉽게 검색 가능하고, 데이터 엔지니어링과 ML 엔지니어링 간의 기술적, 조직적 경계를 명확히 해야 합니다.

	**역 ETL**은 데이터 엔지니어링 수명 주기의 출력 데이터를 원천 시스템으로 되돌려보내는 과정입니다. 이는 SaaS 플랫폼 또는 외부 시스템에 데이터를 다시 푸시하는 데 사용되며, 특히 데이터 웨어하우스에서 고객 데이터 플랫폼(CDP)이나 CRM 시스템으로 데이터를 전달하는 경우에 중요합니다. 역 ETL을 통해 변환된 데이터는 원천 시스템과의 올바른 계통과 비즈니스 프로세스를 통해 다시 공급됩니다.
	
<br>

### ✏️ 2-2. 데이터 엔지니어링 수명 주기의 드러나지 않는 주요 요소

- <span style="color:blue;">**🔥 보안**</span>
	
	데이터 엔지니어는 최소 권한 원칙을 실행하여, 사용자나 시스템이 필요한 데이터와 자원에만 접근할 수 있도록 해야 합니다. 이를 통해 데이터의 불필요한 노출을 방지하고 보안을 강화할 수 있습니다.

	데이터 보호를 위해 암호화, 토큰화, 데이터 마스킹, 난독화와 같은 기술을 사용하여 이동 중인 데이터와 저장된 데이터를 원치 않는 가시성으로부터 안전하게 보호합니다. 이들은 외부에서 데이터에 대한 불법적인 접근을 방지하는 중요한 방법입니다.

	접근 제어는 시스템에서 사용자나 시스템이 특정 자원에 접근할 수 있도록 권한을 세밀하게 관리하는 기능입니다. 이를 통해 불필요한 권한을 제한하고, 데이터와 시스템의 보안을 강화할 수 있습니다.

	또한, IAM(사용자 및 ID 접근 관리)을 통해 역할, 정책, 그룹을 설정하여 각 사용자에게 적절한 권한을 부여하며, 네트워크 보안, 암호 정책 등도 중요한 보안 요소로 작용합니다. 이 모든 방법들을 통해 데이터의 안전성과 시스템의 보안을 확립할 수 있습니다.
	
	
- <span style="color:blue;">**🔥 데이터 관리**</span>

	**데이터 관리**는 데이터와 정보 자산을 수명 주기 전반에 걸쳐 제어하고 보호하며 가치를 향상시키기 위한 계획, 정책, 프로그램을 수립하고 실행하는 과정을 포함합니다. 이는 조직이 보유한 데이터 자산을 체계적으로 관리하고 활용할 수 있도록 돕는 핵심 활동입니다. 데이터 관리의 주요 요소로는 데이터 거버넌스, 데이터 모델링, 데이터 무결성, 데이터 통합 등이 포함되며, 이 모든 요소는 데이터를 최적화하고 안전하게 처리하며 조직의 전략적 목표에 맞게 활용되도록 지원합니다.

	**데이터 거버넌스**는 조직 내에서 데이터의 품질, 무결성, 보안, 사용성을 보장하고, 데이터를 관리하는 조직 내 기능과 정책을 설정하는 중요한 역할을 합니다. 데이터 거버넌스의 핵심은 데이터를 보호하면서도 조직 전체에서 데이터의 가치를 극대화하는 것입니다. 이를 위해 발견 가능성(discoverability), 보안(security), 책임(accountability) 등의 요소를 다룹니다. 특히 발견 가능성은 데이터가 필요한 사람에게 쉽게 제공될 수 있도록 하는 핵심적인 개념이며, 이를 지원하는 데 중요한 역할을 하는 것이 메타데이터입니다. 메타데이터는 데이터에 대한 정보로, 데이터를 검색하고 제어하는 데 필수적입니다. 데이터 엔지니어링 수명 주기에서 메타데이터는 데이터 처리의 기초를 제공하며, 이를 통해 데이터를 효율적으로 관리하고 활용할 수 있습니다.

	**메타데이터**는 비즈니스 메타데이터, 기술 메타데이터, 운영 메타데이터, 참조 메타데이터 등 여러 범주로 나뉘며, 각 카테고리는 데이터가 어떻게 정의되고 처리되는지를 설명합니다.
	
	- 비즈니스 메타데이터는 데이터가 어떻게 비즈니스에서 사용되는지와 관련된 정보를 포함하며, 예를 들어 데이터 정의, 규칙, 데이터 소유자 등이 이에 포함됩니다.
	
	- 기술 메타데이터는 시스템에서 자동으로 생성되는 데이터로, 데이터 모델, 스키마, 필드 매핑 및 데이터 파이프라인 워크플로우와 같은 요소를 포함합니다.
	
	- 운영 메타데이터는 데이터 처리의 성과를 추적하는 데 필요한 정보로, 시스템 로그나 애플리케이션 런타임 로그를 포함합니다.
	
	- 참조 메타데이터는 다른 데이터를 이해하고 해석하는 데 필요한 데이터를 의미하며, 예를 들어 지리적 코드나 측정 단위 등이 이에 포함됩니다.

	**데이터 품질**은 데이터 관리의 중요한 부분으로, 데이터가 정확하고 완전하며 시기 적절하게 제공될 수 있도록 해야 합니다. 정확성(accuracy)은 데이터가 실제로 정확한지, 완전성(completeness)은 데이터 기록이 충분한지, 적시성(timeliness)은 데이터가 적시에 사용 가능한지를 평가하는 기준입니다. 데이터 품질을 보장하는 과정은 데이터의 신뢰성을 확보하고, 분석과 의사결정의 품질을 높이는 데 필수적입니다.

	**마스터 데이터 관리(MDM)**는 조직의 중요한 엔티티 데이터를 관리하는 방법으로, 골든 레코드(golden record)라고 불리는 일관된 데이터 정의를 통해 데이터를 조화시킵니다. 이를 통해 조직 내외부의 데이터가 일관되게 처리되고, 비즈니스 운영에 일관성을 제공할 수 있습니다. 마스터 데이터 관리 시스템은 다양한 소스에서 데이터를 통합하고, 이를 통합된 형식으로 제공함으로써 데이터의 정확성을 유지하고, 중복을 방지합니다.

	**데이터 모델링**은 데이터를 사용 가능한 형태로 변환하는 과정으로, 데이터 엔지니어가 데이터를 구조화하고 설계하는 방법입니다. 데이터 계보는 데이터가 어떻게 변형되었고, 어떤 시스템을 거쳐 갔는지를 추적하는 과정입니다. 데이터 계보는 데이터 수명 주기 동안 데이터의 오류를 추적하고, 시스템에서 발생할 수 있는 문제를 빠르게 식별하는 데 도움을 줍니다. 예를 들어, 데이터가 삭제되거나 변형될 때 해당 데이터의 계보를 통해 데이터를 원래의 위치와 종속성을 추적할 수 있습니다. 이는 데이터의 정확성과 신뢰성을 보장하는 중요한 활동입니다.

	**데이터 통합과 상호 운용성**은 여러 도구와 시스템에서 데이터를 통합하고 상호작용하는 과정으로, 현대의 이기종 시스템 환경에서 매우 중요한 역할을 합니다. 다양한 도구와 시스템에서 데이터를 일관되게 처리하는 것이 점점 더 중요해지고 있으며, 데이터 엔지니어는 이를 통해 다양한 시스템을 효율적으로 연결하고, 데이터를 일관되게 사용할 수 있게 합니다. 예를 들어, 데이터 파이프라인을 통해 Salesforce에서 데이터를 가져와 Amazon S3에 저장하고, Snowflake에서 데이터를 쿼리하고, 이를 다시 S3로 내보내어 Spark에서 처리하는 등의 복잡한 작업을 수행할 수 있습니다. 데이터 시스템 간의 복잡성은 줄어들었지만, 파이프라인의 복잡성은 증가한 상황입니다.

	**데이터 수명 주기 관리**는 데이터를 저장하고 보관하며, 필요시 파기하는 과정을 관리하는 것으로, 데이터의 보안과 규정 준수를 보장하는 중요한 역할을 합니다. 데이터 파기는 법적 요구사항을 충족하기 위해 중요하며, 특히 개인정보 보호법(GDPR, CCPA) 등에 따라 사용자의 개인정보를 적절히 처리하고, 필요한 시점에 데이터를 삭제해야 합니다. 데이터 레이크의 등장으로 데이터를 장기 보관하거나 불필요한 데이터를 파기하는 데 대한 필요성이 커졌습니다. 데이터 파기는 클라우드 환경에서 더욱 복잡할 수 있기 때문에 이를 관리하는 체계적인 접근이 필요합니다.

	**윤리와 개인정보 보호**는 데이터 엔지니어가 데이터 처리 과정에서 개인정보를 적절히 보호하고, 편향을 식별하는 과정입니다. 데이터셋이 개인식별정보(PII)나 민감한 데이터를 포함하는 경우, 이를 마스킹 처리하고, 데이터 변환 과정에서 발생할 수 있는 편향을 추적할 수 있도록 해야 합니다. 데이터의 윤리적 사용은 조직의 신뢰성을 높이고, 법적 위험을 최소화하는 데 기여합니다.
	
	
- <span style="color:blue;">**🔥 데이터 옵스**</span>	

	데이터옵스는 애자일 방법론, 데브옵스, 통계적 공정 관리(SPC) 등의 모범 사례를 데이터 엔지니어링에 적용하는 방식입니다. 데이터옵스의 목표는 데이터 제품에 대한 릴리스와 품질을 개선하는 것인데, 소프트웨어 제품이 사용자에게 특정 기능과 기술적 기능을 제공하는 것과 달리, 데이터 제품은 의사결정을 지원하는 모델과 비즈니스 로직, 측정 지표 등을 기반으로 구축됩니다. 데이터 엔지니어는 이 두 가지 측면을 모두 이해하고 데이터 제품을 효과적으로 구축해야 합니다.

	데이터옵스는 신속한 혁신과 실험을 통해 고객에게 새로운 통찰력을 빠르게 제공하고, 매우 높은 데이터 품질과 낮은 오류율을 유지하며, 인력, 기술, 환경의 복잡한 집합체 전반에 걸쳐 협업하는 것을 목표로 합니다. 또한, 명확한 측정, 모니터링, 결과의 투명성을 통해 데이터 품질을 보장하고, 장기적으로 비즈니스 가치를 향상시킵니다. 이를 통해 데이터 엔지니어는 데이터 옵스 작업의 우선순위를 높여 제품의 신속한 제공과 데이터의 신뢰성 향상, 비즈니스 전반적인 가치 향상에 기여할 수 있습니다.

	데이터옵스의 핵심 기술 요소는 자동화, 모니터링과 관찰 가능성, 사고 대응의 세 가지로 구성됩니다.
	
	**1.자동화**
	
	- 데이터옵스의 자동화는 프로세스의 신뢰성과 일관성을 보장하며, 데이터 엔지니어가 새로운 기능을 기존 워크플로에 신속하게 통합할 수 있게 해줍니다. 이는 코드 및 데이터 버전 관리, 지속적 통합 배포(CI/CD), 그리고 데이터 품질, 모델 드리프트 및 메타데이터 무결성 등을 점검하는 차원을 추가합니다.
		
	- 예를 들어, 데이터 성숙도가 낮은 조직은 간단한 방법으로 데이터를 처리할 수 있으나, 파이프라인이 복잡해질수록 자동화의 중요성이 커집니다. 처음에는 크론 잡을 사용해 데이터 변환 프로세스를 예약하지만, 이는 작업 실패나 예기치 않은 오류를 쉽게 놓칠 수 있습니다. 그러나 조직의 데이터 성숙도가 높아지면, **에어플로**와 같은 오케스트레이션 시스템을 통해 자동화하고 작업 간의 종속성을 관리할 수 있습니다.
		
	**2. 관찰 가능성과 모니터링**
	
	- 페트렐라의 DODD 방법론은 데이터 관찰 가능성을 강조하는 훌륭한 프레임워크로, 데이터와 데이터 애플리케이션에 대한 가시성을 확보하고 그 변경 사항을 추적할 수 있도록 합니다.
	
	- DODD는 데이터 엔지니어링 수명 주기 전반에 걸쳐 데이터를 추적하고 문제가 발생하기 전에 예방하거나 해결할 수 있게 도와줍니다.
	
	**3. 사고 대응(Incident Response)**
	
	- 데이터옵스는 이러한 기술적 요소들을 결합하여, 데이터 파이프라인을 신뢰성 있고 효율적으로 운영합니다.
	
	- 데이터 제품을 빠르게 개발하고 품질을 유지 및 향상 시키는 것에 필수적인 역할을 합니다.
		
		
- <span style="color:blue;">**🔥 데이터 아키텍처**</span>	

	**데이터 아키텍처**는 원천 시스템부터 데이터를 수집하고 저장하며, 변환하고 서빙하는 과정에서 발생하는 설계 패턴, 기술 및 도구의 트레이드오프를 신중히 고려하는 작업입니다. 데이터 엔지니어는 데이터 아키텍트와 협력하여 아키텍처를 구현하고, 그 설계에 대한 피드백을 제공할 수 있어야 합니다. 이는 시스템 전반에서 데이터 흐름을 최적화하고, 각 단계에서 발생할 수 있는 다양한 문제를 해결하기 위해 필수적인 과정입니다.

	데이터 분석 트레이드오프는 다양한 데이터 처리 기술, 성능, 비용, 유지 관리 용이성 등의 요소 간의 균형을 맞추는 것을 의미합니다. 예를 들어, 데이터 파이프라인을 설계할 때 실시간 처리와 배치 처리의 선택, 데이터를 저장하는 데 사용할 시스템(예: 데이터베이스, 데이터 웨어하우스, 데이터 레이크 등)의 선택은 분석에 있어 중요한 트레이드오프입니다.

	데이터 아키텍처는 유연성과 확장성을 고려하여 설계되어야 합니다. 비즈니스 환경이 변화함에 따라 데이터 처리 시스템도 신속하게 적응할 수 있어야 하므로, 민첩성을 확보하는 것이 중요합니다. 시스템은 변화하는 요구사항에 대응할 수 있어야 하며, 이를 위해 모듈화된 설계와 자동화된 배포 파이프라인이 필수적입니다.

	데이터 아키텍처의 목표는 단순히 기술적 요구사항을 충족시키는 것뿐만 아니라, 이를 통해 비즈니스 가치를 창출하는 데 있습니다. 데이터를 효과적으로 수집하고 분석하여 비즈니스 의사결정을 지원하고, 기업 전략에 실질적인 기여를 할 수 있는 데이터 시스템을 구축하는 것이 핵심입니다.
		
		
- <span style="color:blue;">**🔥 오케스트레이션**</span>	

	**오케스트레이션**은 다양한 작업을 효율적이고 빠르게 실행하기 위해 예약된 순서대로 조정하는 프로세스입니다. 이 프로세스는 데이터 엔지니어링과 소프트웨어 개발에서 중요한 역할을 하며, 여러 단계에서 발생할 수 있는 작업 종속성 및 스케줄링 문제를 해결합니다.

	오케스트레이션 엔진은 일반적으로 유향 비순환 그래프(DAG) 형태로 작업 간 종속성을 관리합니다. DAG는 작업들의 순서를 정의하며, 이를 바탕으로 작업을 한 번만 실행하거나, 특정 간격(예: 매일, 매주, 매시간, 5분마다 등)으로 자동으로 실행되도록 설정할 수 있습니다. 이러한 엔진은 시스템의 복잡한 작업을 스케줄링하고 실행할 수 있도록 돕습니다.

	**작업 모니터링 및 오류 처리:**
	
	- 오케스트레이션 시스템은 실행 중인 작업을 모니터링하고, 작업 간의 종속성이 완료되면 새로운 작업을 시작합니다.
	
	- 또한, 외부 시스템과 도구를 모니터링하여 데이터가 도착하거나 조건을 충족하는지 확인하고, 조건이 맞지 않으면 오류를 발생시키며 경고를 보냅니다. 예를 들어, 이메일이나 다른 채널을 통해 경고 메시지를 전송할 수 있습니다.

	**기능 및 시각화:**
	
	- 고급 오케스트레이션 엔진은 작업 기록 기능, 시각화 기능, 경고 기능 등을 제공합니다. 이러한 기능은 작업의 진행 상황을 추적하고, 시스템에서 발생하는 문제를 시각적으로 쉽게 이해할 수 있도록 도와줍니다.
	
	- 또한, **백필 작업(backfill)**과 같은 기능도 지원하여 새로운 DAG 또는 개별 작업을 기존의 종속성에 맞게 추가하거나 재실행할 수 있게 해줍니다.

	**DAG의 이식성 및 테스트:**
	
	- 초기 오픈 소스 프로젝트들은 에어플로(Airflow) 의 핵심 설계를 기반으로 하면서도, DAG의 **이식성(portability)**과 **테스트 가능성(testability)**을 개선하려고 노력했습니다.
	
	- 이들 프로젝트는 엔지니어가 로컬 개발 환경에서 운영 환경으로 쉽게 이동할 수 있도록 돕는 목표를 가지고 있습니다. 대표적인 프로젝트들로는 **프리팩트(Prefect)**와 **대그스터(Dagster)**가 있습니다.
	
	- 이러한 시스템은 더 나은 확장성과 테스트 기능을 제공하며, 개발 및 운영 환경 간의 차이를 최소화하려 합니다.

	**기타 오케스트레이션 엔진:**

	- **아르고(Argo)**는 쿠버네티스(Kubernetes) 프리미티브를 기반으로 구축된 오케스트레이션 엔진으로, 쿠버네티스 환경에서 애플리케이션의 생성과 운영을 최적화하는 데 중점을 둡니다.
	
	- **메타플로(Metaflow)**는 넷플릭스의 오픈 소스 프로젝트로, 데이터 과학 오케스트레이션을 개선하는 데 초점을 맞추고 있습니다. 이는 데이터 과학자의 작업을 효율적으로 관리하고 실험을 추적할 수 있도록 설계되었습니다.
		
		
- <span style="color:blue;">**🔥 소프트웨어 엔지니어링**</span>	

	데이터 엔지니어는 2000년대부터 2010년대 초반까지 주로 C, C++, 자바 등의 저수준 프레임워크에서 맵 리듀스 작업을 작성했습니다. 2010년대 중반 빅데이터 시대에 접어들면서, 엔지니어들은 이러한 저수준의 세부 사항을 추상화한 프레임워크를 사용하게 되었습니다.
	
	**코어 데이터 처리 코드**
	
	데이터 엔지니어는 데이터 수집, 변환, 서빙과 관련된 작업을 스파크, SQL, 빔 등의 프레임워크와 언어를 사용해 수행합니다. 이들은 해당 기술에 능숙하고, 높은 생산성을 유지해야 합니다. 또한, 적절한 코드 테스트 방법론을 이해하는 것이 중요합니다. 이를 통해 단위 테스트, 회귀 테스트, 통합 테스트, 엔드투엔드 테스트, 스모크 테스트 등을 진행할 수 있습니다.

	**오픈소스 프레임워크 개발**
	
	- 데이터 엔지니어는 새로운 내부 도구를 개발하기 전에, 이미 공개된 오픈소스 도구를 검토하는 것이 바람직합니다.
	
	- 기존의 오픈소스 프로젝트가 문제를 해결할 가능성이 크기 때문에, 이를 통해 도구 구현에 소요되는 총소유비용(TCO)과 기회비용을 줄일 수 있습니다.

	**스트리밍**
	
	- 윈도잉 기법을 사용하면 실시간 시스템에서 중요한 통계를 계산할 수 있습니다.
	
	- 엔지니어는 개별 이벤트를 처리하는 다양한 함수 플랫폼(OpenFaaS, AWS Lambda, Google Cloud Functions)이나 실시간 작업을 지원하는 전용 스트리밍 프로세서(스파크, 빔, 플링크, 펄사 등) 중에서 적절한 프레임워크를 선택할 수 있습니다.

	**코드형 인프라(IaC)**
	
	- 빅데이터 시대의 인프라 관리 부담은 데이터브릭스나 아마존 EMR과 같은 관리형 빅데이터 시스템 및 클라우드 데이터 웨어하우스로 전환하면서 감소했습니다.
	
	- 데이터 엔지니어는 클라우드 환경에서 인프라를 관리할 때, 수동으로 인스턴스를 설정하고 소프트웨어를 설치하는 대신 코드형 인프라(IaC) 프레임워크를 사용하여 자동으로 인프라를 배포합니다.
	
	- 또한, 헬름(Helm) 등의 도구를 사용하여 컨테이너와 쿠버네티스를 관리하는 IaC 개념도 확산되고 있습니다. 이는 데브옵스의 중요한 부분으로, 버전 제어와 배포 반복성을 실현합니다.

	**코드형 파이프라인**
	
	- 데이터 엔지니어는 파이썬과 같은 코드로 데이터 작업과 데이터 간의 종속성을 정의하고 관리합니다.
	
	- 이를 통해 효율적인 데이터 파이프라인을 구축합니다.

	**범용 문제 해결**
	
	- 데이터 엔지니어는 Fivetran, Airbyte, Matillion과 같은 프레임워크를 사용할 때, 기존에 커넥터가 없는 데이터 원천에 직면할 수 있습니다.
	
	- 이때, 사용자 정의 코드를 작성하고 API를 이해하여 데이터 풀링 및 변환을 수행하는 등의 소프트웨어 엔지니어링 기술이 필요합니다.