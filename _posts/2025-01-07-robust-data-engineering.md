---
layout: post
title:  "[#4] 견고한 데이터 엔지니어링 공부 (1)"
author: daehong
categories: [ study, data-engineering ]
image: assets/images/robust-data-engineering.jpg
featured: true
rating: 5
---

이 책은 데이터 엔지니어의 역할을 단순히 기업 의사결정을 지원하는 것을 넘어, 데이터의 생성부터 저장, 수집, 변환, 서빙에 이르는 데이터 생명주기 전반에서 ROI를 극대화하고 리스크를 최소화하며 비즈니스에 실질적인 가치를 더하는 데 초점을 맞추고 있습니다.

데이터 관리, 보안, DevOps, 아키텍처, 소프트웨어 엔지니어링 등 다양한 요소를 통합적으로 고려해야 한다는 점에서 데이터 엔지니어를 '데이터 생명주기 엔지니어'로 정의하며, 데이터 엔지니어로서 갖춰야 할 핵심 역량과 본질적인 역할에 대해 깊이 있는 통찰을 제공하고 있습니다.

이 책을 공부함으로써, 데이터 엔지니어링의 기초를 다질 수 있었고, 보다 넓은 시야로 데이터 엔지니어링의 생태계를 볼 수 있는 눈을 얻게 되었습니다.

<br>

## 📚 1장 : 데이터 엔지니어링 기반 구축하기 ️
---

### ✏️ 1-1. 데이터 엔지니어링이란?

- <span style="color:blue;">**🔥 알텍스소프트의 데이터 엔지니어링의 개념, 프로세스 및 도구**</span>

	알텍스소프트에 따르면, 데이터 엔지니어링은 데이터 과학자, 데이터 분석가, 비즈니스 인텔리전스 개발자 등 조직 내 다양한 전문가들이 데이터를 효과적으로 활용할 수 있도록 지원하는 작업의 집합입니다.

	데이터 엔지니어는 대규모 데이터를 수집하고 저장하며, 이를 추가 분석에 적합한 형태로 준비하기 위해 시스템을 설계하고 구축합니다.

	이를 통해 조직의 데이터 인프라를 구축하고 운영하여 데이터 분석과 과학 작업이 원활히 이루어질 수 있도록 돕는 중요한 역할을 합니다.
	

- <span style="color:blue;">**🔥 데이터 엔지니어링 정의**</span>

	데이터 엔지니어링은 원시 데이터를 가져와 분석 및 머신러닝과 같은 다운스트림 사용 사례를 지원하기 위해 고품질의 일관된 정보를 제공하는 시스템과 프로세스를 개발, 구현, 유지 관리하는 작업입니다.
	
	이는 보안, 데이터 관리, 데이터 운영, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링의 교차점에서 이루어집니다.
	
	데이터 엔지니어는 데이터 엔지니어링의 수명 주기를 관리하며, 원천 시스템에서 데이터를 가져오는 것부터 시작해 이를 분석 및 머신러닝과 같은 사용 사례에 활용할 수 있도록 준비하는 과정을 책임집니다.
	
	
- <span style="color:blue;">**🔥 데이터 엔지니어링 생명(수명) 주기**</span>

	데이터 생성(generation) ➜ 데이터 저장(Storage) ➜ 데이터 수집(Ingestion) ➜ 데이터 변환(Transformation) ➜ 데이터 서빙(Serving)
	
	데이터 엔지니어링 수명 주기는 전체 수명 주기에 걸쳐 중요한 아이디어인 드러나지 않는 요소(undercurrent)라는 개념을 포함합니다.
	
	여기에는 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링이 포함됩니다.
	
	
- <span style="color:blue;">**🔥 데이터 엔지니어의 진화**</span>

	데이터 엔지니어링의 역사는 1980년대 데이터 웨어하우스 개념의 형성으로 시작되었습니다. 이 시기에는 IBM의 관계형 데이터베이스와 SQL의 개발, 그리고 오라클에 의한 대중화가 이뤄졌으며, 빌 인먼과 랄프 킴벌은 데이터 모델링 기법과 접근 방식을 발전시켰습니다. 데이터 웨어하우스는 대량의 데이터를 처리하고 확장성 있는 분석 환경을 제공하기 위해 다중 병렬 처리(MPP) 데이터베이스를 도입하며 BI 엔지니어와 ETL 개발자 같은 역할의 중요성을 부각시켰습니다.

	1990년대 중반 인터넷이 주류로 자리 잡으면서 AOL, 야후, 아마존 같은 웹 우선(web-first) 기업이 등장했고, 닷컴 열풍은 웹 애플리케이션과 이를 지원하는 백엔드 시스템에서 엄청난 활동을 일으켰습니다. 당시 대부분의 인프라는 비용이 많이 들고 비효율적이었지만, 데이터와 시스템의 중요성이 점점 커졌습니다.

	2000년대 초, 닷컴 버블이 무너진 후 생존한 기업들(야후, 구글, 아마존 등)은 기존의 전통적인 모놀리식 데이터베이스와 데이터 웨어하우스를 한계까지 밀어붙이며 데이터 처리 문제를 해결하기 위해 혁신을 모색했습니다.
	
	구글은 2003년 구글 파일 시스템 논문과 2004년 맵리듀스 논문을 발표하며 대규모 데이터 처리의 새로운 패러다임을 제시했습니다. 이 논문들은 야후 엔지니어들에 의해 아파치 하둡의 개발로 이어졌고, 기업들은 점차 테라바이트와 페타바이트 규모의 데이터를 다루기 시작했습니다.

	같은 시기, 아마존은 EC2, S3, 다이나모DB 같은 데이터 빌딩 블록을 구축하며 클라우드 컴퓨팅의 가능성을 열었습니다. AWS의 성공은 구글 클라우드, 마이크로소프트 애저 등 퍼블릭 클라우드의 등장을 촉진하며 데이터 애플리케이션 개발과 배포 방식을 혁신했습니다.

	2000년대와 2010년대에는 하둡 생태계를 중심으로 한 오픈 소스 빅데이터 도구들이 급격히 성숙했습니다. 하둡, 스파크, 하이브, 카산드라 같은 기술이 발전하며 데이터 엔지니어링은 배치 처리에서 이벤트 스트리밍으로 전환되었고, 실시간 빅데이터 시대가 열렸습니다. 이 시기의 빅데이터 엔지니어는 대규모 클러스터를 유지 관리하고, 코드 우선(code-first) 방식으로 데이터 처리를 최적화하며 기존의 GUI 중심 도구를 대체했습니다.

	2020년대에 들어 데이터 엔지니어링은 또 한 번의 변화를 겪고 있습니다. 기존의 하둡이나 인포매티카 같은 모놀리식 프레임워크에서 벗어나 점점 더 분산되고 모듈화된, 고도로 추상화된 도구들이 주류가 되고 있습니다. 데이터 엔지니어는 다양한 기술을 연결하고 상호 운용하며 비즈니스 목표를 지원하는 데 초점을 맞추고 있습니다.

	이제 데이터 엔지니어는 단순히 데이터를 처리하고 제공하는 역할을 넘어 데이터 수명 주기 전반을 관리하며, 보안, 개인정보 보호, 규정 준수 같은 가치 사슬의 상위 영역에 집중하고 있습니다. CCPA, GDPR 같은 데이터 규정을 숙지하고, 파이프라인 설계 시 개인정보 보호와 익명화, 데이터 품질 및 규정 준수를 고려하는 등 데이터 엔지니어링의 역할은 기술적 과제와 비즈니스 요구를 동시에 해결하는 방향으로 진화하고 있습니다.
	
<br>
	
### ✏️ 1-2. 데이터 엔지니어링 기술과 활동

데이터 엔지니어링은 단순히 데이터를 처리하는 기술적인 측면만을 포함하는 것이 아니라, 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처 및 소프트웨어 엔지니어링과 같은 여러 핵심 요소들이 숨어 있는 복잡한 작업입니다.

데이터 엔지니어는 이러한 다양한 복잡한 가변적인 요소를 처리하며, 비용, 민첩성, 확장성, 단순성, 재사용성, 상호 운용성 등을 고려하여 지속적으로 시스템을 최적화해야 합니다.

- <span style="color:blue;">**🔥 데이터 성숙도와 데이터 엔지니어**</span>

	데이터 성숙도는 조직이 더 높은 데이터 활용률, 기능, 통합을 달성하려는 과정입니다.
	
	데이터 성숙도가 높아질수록 조직은 데이터를 보다 효과적으로 활용할 수 있고, 이를 통해 비즈니스 경쟁력을 강화할 수 있습니다. 데이터 성숙도를 위한 단계는 기업마다 다르지만, 일반적으로 단순화된 기업용 데이터 성숙도 모델을 따르게 됩니다.

	**데이터로 시작하기 단계**에서는, 데이터 엔지니어는 기업의 목표를 지원하는 데이터 아키텍처를 설계하고 구축하는 데 중요한 역할을 합니다. 또한, 데이터를 다루는 이니셔티브를 통해 달성하려는 경영 목표와 경쟁 우위를 결정하고, 이를 지원하는 데이터 아키텍처를 구축하는 것이 필수적입니다. 이 과정에서 데이터 아키텍트가 없을 경우, 데이터 엔지니어가 홀로 진행할 수 있습니다.

	**데이터로 확장하기 단계**에서는 데이터 엔지니어는 조직 내에서 공식적인 데이터 관행을 수립하고, 확장 가능하고 견고한 데이터 아키텍처를 구축하며, 데브옵스 및 데이터옵스 관행을 채택해야 합니다. 또한, 머신러닝(ML)을 지원하는 시스템을 구축하고, 경쟁 우위를 확보할 수 있는 부분에 대해서만 커스터마이징을 수행합니다.

	**데이터로 선도하기 단계**에서는 이전 단계를 계속해서 확장하며, 새로운 데이터의 매끄러운 배포와 사용을 위한 자동화를 구축합니다. 또한, 데이터를 경쟁 우위로 활용하기 위한 사용자 정의 도구와 시스템을 구축하는 데 집중하고, 데이터 관리 및 데이터옵스와 같은 기업 차원의 데이터 측면에 집중합니다. 이때 데이터 카탈로그, 데이터 계보 도구, 메타데이터 관리 시스템을 포함하여 데이터를 조직 전체에 효율적으로 노출하고 전파하는 도구를 배포합니다. 또한, 소프트웨어 엔지니어, ML 엔지니어, 분석가 등과 협력하며, 협업과 공개적인 토론이 가능한 커뮤니티와 환경을 조성하는 것이 중요합니다.


- <span style="color:blue;">**🔥 데이터 엔지니어의 배경과 기술**</span>

	데이터 엔지니어는 데이터와 기술을 모두 이해해야 하며, 데이터 관리의 모범 사례와 더불어 도구의 다양한 옵션, 상호작용, 상충 관계를 숙지해야 합니다.
	
	이를 위해 소프트웨어 엔지니어링, 데이터옵스, 데이터 아키텍처에 대한 이해가 필수적입니다.
	

- <span style="color:blue;">**🔥 기술 책임과 데이터 엔지니어링의 주요 언어**</span>

	최근 들어 완전 관리형 서비스가 등장하면서 데이터 엔지니어들은 과거의 복잡한 저수준 프로그래밍 작업에서 벗어나, 고수준의 추상화 작업이나 오케스트레이션 프레임워크 내에서 파이프라인을 코드로 작성하는 일에 더 집중하게 되었습니다.

	데이터 엔지니어링에서 사용하는 주요 언어로는 SQL이 있습니다. SQL은 스파크 SQL, 구글 빅쿼리, 스노우플레이크, 하이브와 같은 도구에서 대량의 데이터를 처리하는 데 사용되며, 아파치 플링크, 빔, 카프카와 같은 스트리밍 프레임워크에서도 지원됩니다.

	또한, Python, Java, Scala와 같은 언어도 데이터 엔지니어링에서 중요한 역할을 합니다. 특히 **Java Virtual Machine (JVM)**은 스파크, 하이브, 드루이드와 같은 오픈 소스 프로젝트에서 널리 사용되며, 파이썬보다 성능이 뛰어나고 저수준의 기능에 접근할 수 있는 장점이 있습니다. 따라서 자바와 스칼라를 이해하면 오픈 소스 데이터 프레임워크 활용에 큰 도움이 됩니다.

	이외에도 Bash는 간단한 작업 자동화와 스크립팅에 널리 사용되며, 필요에 따라 R, JavaScript, Go, Rust, C/C++, C#, Julia와 같은 언어도 활용됩니다.
	
	이러한 다양한 언어들은 데이터 엔지니어의 역량을 넓히고, 특정 데이터 처리 및 분석 요구를 충족하는 데 중요한 역할을 합니다.
	
	
	
- <span style="color:blue;">**🔥 A에서 B로 이어지는 데이터 엔지니어링 역할의 연속성**</span>
	
	**"A형 데이터 엔지니어"**
	
	A는 **추상화(Abstraction)**를 의미합니다.
		
	A형 데이터 엔지니어는 데이터 아키텍처를 단순하고 추상적으로 유지하며, 차별화되지 않은 과중한 작업을 피하려 노력합니다.
		
	이들은 기성 제품, 관리형 서비스, 그리고 SaaS 도구를 주로 사용하여 데이터 엔지니어링 수명 주기를 관리합니다.
		
	A형 데이터 엔지니어는 데이터 성숙도와 무관하게 다양한 산업과 회사에서 널리 활동합니다.
	
	**"B형 데이터 엔지니어"**
	
	B는 **구축(Build)**을 의미합니다.
		
	B형 데이터 엔지니어는 기업의 핵심 경쟁력을 확장하고 지원할 수 있는 맞춤형 데이터 도구와 시스템을 설계하고 구축합니다.
		
	이들은 주로 데이터 성숙도의 **2단계(데이터로 확장하기)**와 **3단계(데이터로 선도하기)**에 해당하는 기업이나, 초기 데이터 사용 사례가 독특하고 중요해 맞춤형 도구가 필요한 조직에서 활발히 활동합니다.
	
	**이 두 유형은 서로 상호 보완적인 역할을 하며, 데이터 엔지니어링의 다양한 요구를 충족시키기 위해 긴밀히 협력합니다.**

<br>

### ✏️ 1-3. 조직 내 데이터 엔지니어

- <span style="color:blue;">**🔥 내부 대면 vs 외부 대면 데이터 엔지니어**</span>

	**"1. 외부 대면 데이터 엔지니어"**
	
	외부 대면 데이터 엔지니어는 외부 사용자와 연계되는 애플리케이션을 지원하는 데 초점을 맞춥니다.
	
	이들은 소셜 미디어 앱, 사물 인터넷(IoT) 장치, 전자 상거래 플랫폼과 같은 외부 애플리케이션에서 생성되는 트랜잭션과 이벤트 데이터를 처리합니다.
	
	주요 역할로는 이러한 데이터를 수집, 저장, 처리하기 위한 시스템의 설계, 구축, 그리고 관리를 포함합니다.
	
	**"2. 내부 대면 데이터 엔지니어"**
	
	내부 대면 데이터 엔지니어는 비즈니스 및 내부 이해관계자의 요구를 충족시키는 활동에 집중합니다.
	
	이들은 BI 대시보드와 보고서를 생성하거나, 데이터 과학 및 머신러닝 모델을 위한 데이터 파이프라인과 데이터 웨어하우스를 설계하고 유지 관리합니다.
	
	내부 데이터를 활용하여 조직 내에서 더 나은 의사결정을 지원하는 것이 이들의 주요 목표입니다.
	
	
- <span style="color:blue;">**🔥 데이터 엔지니어와 기타 기술 역할**</span>

	데이터 엔지니어는 소프트웨어 엔지니어, 데이터 아키텍트, 데브옵스 엔지니어 또는 사이트 신뢰성 엔지니어(SRE) 같은 데이터 생산자(data producer)와 데이터 분석가, 데이터 과학자, ML 엔지니어 등과 같은 데이터 소비자(data consumer)사이에서 허브 역할을 합니다.
	
	또한 데이터 엔지니어는 데브옵스 엔지니어와 같이 운영 역할을 하는 사람들과 소통합니다.

	
- <span style="color:blue;">**🔥 데이터 엔지니어와 업스트림 이해관계자**</span>

	**데이터 아키텍트**는 조직의 데이터 관리를 위한 청사진을 설계하고, 데이터 아키텍처 및 프로세스를 매핑합니다. 이들은 사일로를 제거하고 데이터 관리 및 거버넌스 전략을 조율하며, 클라우드 마이그레이션과 신규 설계 프로젝트에서 핵심적인 역할을 합니다.
	
	**소프트웨어 엔지니어**는 비즈니스 운영을 지원하는 애플리케이션과 시스템을 개발합니다. 이 과정에서 생성되는 애플리케이션 이벤트 데이터와 로그는 데이터 엔지니어가 사용하는 중요한 내부 데이터 자산입니다.

	**데브옵스 엔지니어와 SRE(Site Reliability Engineer)**는 시스템 운영과 모니터링을 통해 데이터를 생성하며, 데이터 엔지니어는 이들과 협력해 데이터 파이프라인의 안정성과 효율성을 개선합니다.


- <span style="color:blue;">**🔥 데이터 엔지니어와 다운스트림 이해관계자**</span>

	**데이터 과학자**는 데이터를 분석하여 미래를 예측하고 추천 시스템을 설계합니다. 데이터 엔지니어는 이들이 작업에 필요한 데이터 준비를 돕고, 모델 배포와 확장을 지원하며 데이터 과학 워크플로의 효율성을 높입니다.
	
	**데이터 분석가**는 주로 과거와 현재의 데이터를 분석하여 비즈니스 성과를 파악합니다. 이들은 SQL 쿼리와 BI 도구를 활용하며, 데이터 정의 및 품질 문제에 정통한 도메인 전문가로서 조직의 의사결정 과정에 기여합니다.

	**머신러닝 엔지니어**는 고급 머신러닝 모델을 설계하고 훈련하며, 이를 운영 환경에 배포합니다. 데이터 엔지니어는 이들과 협력하여 ML 워크플로를 지원하고, 클라우드 기반 환경에서 모델의 확장 가능성을 보장합니다.

<br>
<br>

## 📚 2장 : 데이터 엔지니어링 수명 주기
---

### ✏️ 2-1. 데이터 엔지니어링 수명 주기란?

**데이터 엔지니어링 수명 주기** : 원시 데이터의 요소를 분석가, 데이터 과학자, ML 엔지니어 등이 사용할 수 있는 유용한 최종 제품으로 전환하는 단계로 구성됩니다.

- <span style="color:blue;">**🔥 데이터 생성**</span>

	원천 시스템은 데이터 엔지니어링 수명 주기에서 사용되는 데이터의 원본입니다. 예를 들어, IoT 장치, 애플리케이션 메시지 대기열, 트랜잭션 데이터베이스 등이 원천 시스템이 될 수 있습니다. 데이터 엔지니어는 원천 시스템의 작동 방식, 데이터 생성 방식, 빈도, 속도, 그리고 데이터의 다양성을 실무적으로 이해해야 합니다.

	원천 시스템 평가에 있어 주요 엔지니어링 고려 사항은 데이터 원천의 본질적인 특징을 이해하는 것입니다. 원천 시스템이 애플리케이션인지, IoT 장치의 스웜인지 등을 파악해야 합니다. 또한 데이터가 어떻게 유지되는지, 장기간 보존되는지 아니면 일시적으로 삭제되는지 확인해야 합니다. 데이터는 어떤 속도로 생성되며, 초당 몇 개의 이벤트나 시간당 몇 기가바이트가 발생하는지도 중요한 요소입니다.

	데이터 엔지니어는 출력 데이터에서 일관성을 기대할 수 있는 정도를 평가해야 합니다. 데이터 품질 검사에서 예기치 않은 출력값이나 잘못된 데이터 포맷과 같은 불일치 사례가 얼마나 자주 발생하는지도 고려해야 합니다. 또한, 에러 빈도와 데이터의 중복 여부, 데이터 도착 시점에 대한 문제도 평가해야 합니다.

	수집된 데이터의 스키마와 이를 완전히 파악하기 위해 여러 테이블이나 시스템에 걸쳐 조인해야 하는지에 대한 여부도 중요한 평가 요소입니다. 스키마가 변경될 때의 대응 방안과 다운스트림 이해관계자에게 이를 전달할 방법도 고려해야 합니다. 또한, 원천 시스템에서 데이터를 얼마나 자주 가져와야 하는지에 대한 여부와, 상태가 있는 시스템의 경우 데이터가 스냅숏 형태로 제공되는지, 변경 데이터 캡처(CDC)를 통해 갱신 이벤트로 제공되는지 확인해야 합니다.

	원천 시스템의 데이터 조회가 성능에 미치는 영향, 업스트림 시스템의 데이터 의존 관계, 늦거나 누락된 데이터 확인을 위한 데이터 품질 검사 실시 여부도 고려해야 합니다. 스키마리스 방식은 스키마가 없다는 의미가 아니라, 애플리케이션이 메시지 대기열, 플랫 파일, BLOB 또는 도큐먼트 데이터베이스에서 데이터가 기록될 때 스키마를 정의하는 방식입니다. 관계형 데이터베이스에서는 고정 스키마 방식을 사용하며, 애플리케이션은 이를 준수해야 합니다.


- <span style="color:blue;">**🔥 데이터 저장**</span>

	스토리지 시스템 평가에 있어 데이터 웨어하우스, 데이터 레이크하우스, 데이터베이스 또는 객체 스토리지의 선택은 몇 가지 중요한 엔지니어링 질문을 기반으로 진행됩니다. 우선, 해당 스토리지 솔루션이 아키텍처에서 요구하는 쓰기 및 읽기 속도와 잘 맞는지 확인해야 합니다. 또한, 스토리지가 다운스트림 프로세스의 병목 현상을 초래하지 않는지도 점검해야 합니다.

	스토리지 시스템이 어떻게 작동하는지 이해하고, 이를 최적으로 활용하는지 확인하는 것이 중요합니다. 예를 들어, 객체 스토리지 시스템에서 높은 비율의 임의 접근 갱신을 적용하는 것은 성능 오버헤드가 큰 안티패턴이 될 수 있습니다. 또한, 스토리지 시스템이 향후 예상되는 확장을 처리할 수 있는지도 고려해야 합니다. 사용 가능한 총 스토리지, 읽기 작업 속도, 쓰기 볼륨 등 스토리지 시스템의 용량 제한을 점검해야 합니다.

	다운스트림 사용자와 프로세스가 필요한 서비스 수준 협약(SLA)에 따라 데이터를 취득할 수 있는지도 중요한 평가 요소입니다. 또한, 스키마 진화, 데이터 흐름, 데이터 계보 등에 대한 메타데이터를 캡처하고 있는지 확인해야 합니다. 메타데이터는 데이터 활용성에 큰 영향을 미치며, 미래의 프로젝트와 아키텍처 변경을 간소화할 수 있습니다.

	스토리지 시스템이 순수 스토리지 솔루션인지, 아니면 복잡한 쿼리 패턴을 지원하는지 (예: 클라우드 데이터 웨어하우스) 확인하는 것도 필요합니다. 또한, 스토리지 시스템이 스키마에 구애받지 않는지, 유연한 스키마를 제공하는지, 아니면 강제된 스키마가 있는지 점검해야 합니다. 데이터 거버넌스를 위해 마스터 데이터, 골든 레코드 데이터 품질 및 데이터 계보를 어떻게 추적하고 있는지, 그리고 법령 준수 및 데이터 주권을 어떻게 대처하는지도 중요한 요소입니다.

	데이터 접근 빈도에 따라 데이터 온도도 결정됩니다. 핫 데이터는 가장 자주 액세스되는 데이터로, 빠른 검색을 위해 저장되어야 합니다. 미온적 데이터는 가끔 액세스되는 데이터로, 적절한 저장 방식이 필요합니다. 콜드 데이터는 거의 쿼리되지 않으며, 아카이브 시스템에 저장되는 데이터로, 규정 준수나 장애 복구 목적 등으로 보관될 수 있습니다.


- <span style="color:blue;">**🔥 데이터 수집**</span>

	데이터 수집 단계에서 중요한 엔지니어링 고려 사항은 여러 가지가 있습니다. 먼저, 수집 중인 데이터의 사용 사례를 정의해야 합니다. 같은 데이터셋의 여러 버전을 생성하는 대신 데이터를 재사용할 수 있는지 평가해야 합니다. 또한, 시스템이 데이터를 안정적으로 생성하고 수집하는지, 그리고 필요할 때 데이터를 사용할 수 있는지 확인해야 합니다.

	수집 후 데이터의 목적지도 중요한 고려 사항입니다. 데이터가 얼마나 자주 접근되어야 하는지, 도착하는 데이터의 용량, 그리고 데이터 형식은 무엇인지도 파악해야 합니다. 이러한 형식을 다운스트림 스토리지와 변환 시스템이 처리할 수 있는지도 확인해야 합니다. 원천 데이터가 다운스트림에서 즉시 사용할 수 있는 상태인지, 그렇다면 얼마나 오래 사용할 수 있는지, 사용할 수 없게 되는 요인은 무엇인지를 평가해야 합니다.

	데이터가 스트리밍 소스에서 전송되는 경우, 목적지에 도달하기 전에 데이터를 변환해야 하는지 여부도 중요한 질문입니다. 데이터가 스트림 내에서 변환되는 것이 적절한지, 혹은 다른 형태의 변환이 필요한지 고려해야 합니다.

	**"배치 수집과 스트리밍 수집에 대한 고려 사항도 필수적입니다."**
	
	스트리밍 수집은 데이터를 실시간으로 제공할 수 있는 방법으로, 이벤트 스트리밍과 처리 플랫폼의 발전으로 더욱 인기를 얻고 있습니다. 배치 수집은 데이터를 일정한 시간 간격으로 큰 청크로 처리하는 방법으로, 분석 및 머신러닝에 적합합니다.

	배치와 스트리밍 수집의 주요 차이점은 데이터 처리 방식과 실시간 데이터 수집의 필요성 여부입니다. 스트리밍 수집이 배치 수집보다 더 적합한지 여부를 판단하려면, 다운스트림 시스템이 데이터를 실시간으로 처리할 수 있는지, 그리고 실시간 수집의 밀리초 단위로 데이터를 축적하고 수집하는 마이크로 배치 접근이 효과적인지 평가해야 합니다.

	스트리밍 수집을 사용할 때 얻을 수 있는 구체적인 이점과 개선된 데이터 처리 방안도 고려해야 합니다. 또한, 스트리밍 우선 접근 방식이 시간, 비용, 유지 보수, 다운타임 및 기회비용 측면에서 더 많은 비용을 소비할지 여부를 평가해야 합니다.

	데이터 수집 시스템이 안정적이고 다중화되어 있는지, 장애 발생 시 어떻게 대응할 수 있는지도 점검해야 합니다. 수집에 가장 적합한 도구로는 관리형 서비스나, Kafka, Flink, Spark, Pulsar와 같은 인스턴스를 선택할 수 있습니다. 후자의 경우, 관리 역할과 비용, 트레이드오프를 고려해야 합니다.

	**"푸시와 풀 방식은 데이터 수집에서 중요한 두 가지 모델입니다."**
	
	푸시 모델에서는 원천 시스템이 타깃에 데이터를 씁니다. 풀 모델에서는 수집 시스템이 원천 시스템에서 데이터를 검색합니다. ETL 프로세스에서는 일반적으로 풀 모델을 사용하며, 추출 부분은 정해진 일정에 따라 소스 테이블을 쿼리합니다.

	또한, 연속적인 CDC(변경 데이터 캡처) 방식도 고려해야 합니다. 이는 원천 데이터베이스에서 변경된 데이터를 실시간으로 추적하고 메시지를 트리거하여 수집 시스템이 이를 처리하는 방식입니다. 바이너리 로그를 사용하는 CDC 방식은 원천 데이터베이스에 추가적인 부하를 주지 않으면서 데이터를 처리할 수 있습니다.
	
	Kafka 의 컨슈머나, Spark 등에서는 Pull 방식을 이용하며, RabbitMQ 등에서는 Push 방식을 이용합니다.
	
	
- <span style="color:blue;">**🔥 데이터 변환**</span>

	데이터 변환 단계에서 고려해야 할 주요 사항은 다음과 같습니다.

	먼저, 변환에 드는 비용을 평가해야 합니다. 변환이 비즈니스에 미치는 가치를 이해하고, 변환 작업이 제공하는 비즈니스 가치를 명확히 해야 합니다. 이를 통해 변환 작업이 얼마나 중요한지, 그리고 이에 대한 자원을 할당할 만한 가치가 있는지를 판단할 수 있습니다.

	다음으로, 변환이 가능한 한 단순하고 독립적인지 확인해야 합니다. 복잡한 변환 작업은 오류 가능성을 높이고 유지 보수를 어렵게 만들 수 있으므로, 가능한 한 간단하게 구성하는 것이 좋습니다. 독립적인 변환은 시스템이나 다른 작업에 영향을 미치지 않고 개별적으로 수행될 수 있어 유리합니다.

	또한, 변환이 지원하는 비즈니스 규칙은 무엇인지 파악해야 합니다. 데이터 변환은 종종 비즈니스 규칙을 기반으로 하여 데이터를 형식에 맞게 정리하거나 변환하는 작업을 수행하므로, 이러한 규칙을 정확히 이해하고 준수하는 것이 중요합니다.
	
	
- <span style="color:blue;">**🔥 데이터 서빙**</span>

	데이터 서빙은 수집, 저장, 변환 후에 데이터로부터 가치를 창출하는 과정입니다. 이 단계에서는 분석 및 비즈니스 인텔리전스(BI), 운영 분석, 임베디드 분석, 머신 러닝, 역 ETL 등 다양한 영역이 고려됩니다.

	데이터 허영(data vanity) 프로젝트는 기업의 주요 리스크가 될 수 있으며, 많은 기업들이 불필요한 대규모 데이터셋을 수집하여 유용하게 활용되지 않는 데이터 레이크를 만들어 놓는 실수를 범하고 있습니다.

	**분석 단계**에서는 데이터를 저장하고 변환한 후, 보고서 또는 대시보드를 생성하고 임시 분석을 통해 데이터를 활용할 수 있습니다. 비즈니스 인텔리전스(BI)는 기업 경영의 과거와 현재 상태를 설명하기 위해 데이터를 수집하고, 비즈니스 로직을 통해 원시 데이터를 처리합니다. 기업의 데이터 성숙도가 높아짐에 따라, 비즈니스 사용자가 IT 부서의 개입 없이도 셀프서비스 분석을 할 수 있게 됩니다. 그러나 셀프서비스 분석은 데이터 품질 저하, 조직 사일로 현상, 적절한 데이터 기술 부족 등으로 어려움이 있을 수 있습니다. 운영 분석은 재고 물품이나 웹사이트, 애플리케이션 상태 등의 실시간 뷰를 제공하는 대시보드로, 사용자가 즉시 수행할 수 있는 작업을 촉진합니다. 임베디드 분석은 고객에게 분석 결과를 제공할 수 있는 기능으로, 대규모 고객에게 데이터와 분석을 제공할 수 있습니다. 이때 각 고객은 자신의 데이터만 확인할 수 있어야 하며, 데이터 유출과 보안 취약성에 대한 대응이 중요합니다.

	**머신 러닝**에서는 신뢰할 수 있는 특성 엔지니어링과 충분한 품질의 데이터가 필요하며, 데이터가 실제 상황을 잘 반영하고 불공평하게 편향되지 않았는지 확인해야 합니다. 또한, 데이터가 쉽게 검색 가능하고, 데이터 엔지니어링과 ML 엔지니어링 간의 기술적, 조직적 경계를 명확히 해야 합니다.

	**역 ETL**은 데이터 엔지니어링 수명 주기의 출력 데이터를 원천 시스템으로 되돌려보내는 과정입니다. 이는 SaaS 플랫폼 또는 외부 시스템에 데이터를 다시 푸시하는 데 사용되며, 특히 데이터 웨어하우스에서 고객 데이터 플랫폼(CDP)이나 CRM 시스템으로 데이터를 전달하는 경우에 중요합니다. 역 ETL을 통해 변환된 데이터는 원천 시스템과의 올바른 계통과 비즈니스 프로세스를 통해 다시 공급됩니다.