---
layout: post
title:  "[#2] Apache Iceberg Deep Dive - How Does It Address the Limitations of Hive?"
author: daehong
categories: [ Apache, Iceberg, Bigdata ]
image: assets/images/apache-iceberg.png
featured: true
rating: 5
---

**Apache Iceberg**는 Toss, Kakao, 11번가, LINE 할 거 없이 많은 곳에서 도입하고 있는 테이블 포멧 형태의 기술이며, 심지어 네이버 웹툰에서는 아이스버그 구축 경험이 있는 사람을 대놓고 우대사항에 적어두고 있을만큼, 이름과는 상반되게 현재 뜨겁게 타오르는 태양과도 같은 기술입니다.

새로운 기술을 접목 하는데에 있어, 기업과 개발자의 관점은 같으면서도 다른 것을 중점으로 두고 있습니다. 기업은 해당 기술을 도입함으로써, 얼만큼의 금전적 이윤을 얻을 수 있는지를 추구하고, 개발자는 그 기술을 도입함으로써 자신의 기술적 스킬 향상과 가치를 상승 시킬 수 있습니다.

이렇게 이윤과 성장이라는 다른 중점은 가지고 있지만, 이익을 추구한다는 관점은 같다고 볼 수 있습니다.

그러한 면에서 **Apache Iceberg** 은 기업 입장에서도, 개발자 입장에서도 반드시 도입해야 할 기술이라는 결론을 먼저 말씀드리며, 지금부터 왜 **Apache Iceberg**를 도입해야 하는지, 대체 **Apache Iceberg**가 무엇인지 이 거대한 빙산을 조금씩 녹여가며 중요한 부분들에 대해 이야기하도록 하겠습니다.

<br>

<div style="background-color: pink; padding: 5px; margin: 0;">
  <h2 style="margin: 0;">🧊🧊 1. Apache Iceberg 란 ?</h2>
</div>
---

**Apache Iceberg**는 **2017년 Netflix**에서 **Apache Hive**의 한계를 극복하기 위해 개발된 개방형 테이블 형식의 데이터 관리 시스템입니다. 대규모 데이터 세트를 효율적으로 관리하고 처리하기 위한 목적으로 만들어졌으며, 현재는 **Apache** 재단에 기부된 오픈소스 프로젝트입니다. 데이터 엔지니어들 사이에서는 데이터를 효과적으로 관리하고 실시간으로 **쿼리(Query)**할 수 있는 도구로 주목받으며 최근 큰 인기를 끌고 있습니다.

**Apache Hive**의 주요 한계로는 **ACID 지원 부족, MetaStore의 병목 현상, Schema 확장성의 한계, 디렉터리 및 파일 조회 시간 문제, 파티션 필터링의 비효율성, 그리고 높은 지연 시간(Latency)** 등이 꼽힙니다.

이렇게만 설명하면 다소 추상적으로 느껴질 수 있으니, 몇 가지 예시를 통해 더 자세히 설명드리겠습니다.

<br>

<span style="background-color: lightblue;"><h3>&nbsp;🧊 1.1. Hive 의 한계 : 불완전한 ACID 지원&nbsp;</h3></span>
---

**첫 번째 예시입니다.**

은행에서 고객 거래 데이터를 분석해 더 나은 서비스와 맞춤형 금융 상품을 제공하고자 합니다.  고객들의 입출금 내역, 카드 사용 내역, 그리고 온라인 뱅킹 활동 데이터를 수집해 **Apache Hive**에 적재한 상태입니다.

어느 날, 마케팅 팀이 특정 고객군의 월별 카드 사용 패턴을 분석하려 합니다. 데이터 엔지니어링 팀은 고객 데이터를 **Hive**에 적재하고, ETL 작업을 통해 분석 가능한 상태로 만들어 제공했습니다. 그런데 문제가 생겼습니다. 같은 시간대에 IT 운영팀에서도 동일한 데이터셋을 이용해 대규모 업데이트 작업을 수행하고 있던겁니다.

**Hive**는 기본적으로 파일 기반의 저장소를 사용하므로, 두 작업이 동시에 실행되면서 다음과 같은 문제가 발생했습니다.

- IT 운영팀이 데이터를 업데이트하는 과정에서 일부 파일이 교체되었습니다. 마케팅 팀이 분석 쿼리를 실행하는 중간에 데이터가 변경되었고, 그 결과 마케팅 팀이 가져간 데이터는 절반은 업데이트 전, 나머지 절반은 업데이트 후 상태였습니다. 즉, 일관성이 깨져 분석 결과가 신뢰할 수 없게 되었습니다.
- 또 다른 문제는 IT 운영팀이 데이터를 병렬로 덮어쓰는 과정에서 일부 파일이 잘못 덮어써지거나 손실되었습니다. **Hive**는 **INSERT OVERWRITE** 방식으로 동작하므로, 중복 작업이나 오류가 발생하면 데이터를 복구하기 어렵습니다.
- 이 모든 과정에서 두 팀이 동시에 Hive 테이블을 읽고 쓰면서 경합이 발생했습니다. 특정 쿼리는 파일이 존재하지 않거나 잠겨 있어 실패했고, 결과적으로 분석팀의 업무가 지연되었습니다.

이렇게 데이터가 유실되거나, 읽기/쓰기 과정에서 충돌이 발생하여 업무가 지연되는 일이 발생 할 수 있습니다.

물론 현재는 **Hive** 에서도 현재 ACID  트랜잭션을 활성화 시키면, 일부 ACID 를 지원해주기는 합니다. 그러나 트랜잭션 작업 시 바로 원본 데이터 파일에 반영되는 것이 아니라 별도의 **Delta 파일**이 생성되고, **Delta 파일**이 **Compaction**되는 과정을 통하여 원본 파일의 ACID 를 보장하는 절차를 가지고 있습니다.

이로 인하여 별도의 Compaction 작업으로 인한 비용 문제와, Delta 파일이 증가함에 따라 빈번하게 발생하는 Compaction 작업으로 인한 병목 현상, 이러한 작업으로 인한 실시간 데이터 분석의 어려움 문제가 있으며, 무엇보다 ORC 파일 포맷 형식만 ACID 를 지원하므로 csv 나 다른 형식의 포맷은 이용 할 수 없다는 큰 단점이 있습니다.

<br>

### 🧊 1.2. Hive 의 한계 : MetaStore 의 병목 현상
---

**두 번째 예시입니다.**

이번에도 마찬가지로, 은행에서 데이터를 분산 환경에서 HDFS 에 저장하고, **Apache Hive** 를 통하여 관리하고 있습니다.

- 은행은 각 거래 기록을 날짜별로 파티셔닝된 테이블에 저장합니다.
- 테이블은 **고객 계좌 번호(account_id)**를 기준으로 추가적인 서브 파티셔닝이 되어 있어, 하루에 생성되는 파티션 수는 수천 개에 이릅니다.
- 하루 동안 약 **100만 건의 거래 데이터**가 발생하며, 이를 조회하고 분석하기 위해 여러 사용자가 Hive를 동시에 사용합니다.

이 때 다음과 같은 집계와, 보고서를 생성하기 위해, 여러 부서에서 동시에 해당 데이터로 접근을 합니다.

**일 별 거래 집계 쿼리**

```sql
SELECT account_id, SUM(transaction_amount) AS daily_total
FROM transactions
WHERE transaction_date = '2024-12-01'
GROUP BY account_id;
```

**주별 보고서 생성 ( 대시보드 반영을 위해 )**

```sql
SELECT account_id, SUM(payment_amount) AS weekly_payment
FROM loan_payments
WHERE payment_date BETWEEN '2024-11-25' AND '2024-12-01'
GROUP BY account_id;
```

이 작업이 실행되면서 **MetaStore**에 과부하가 걸리기 시작합니다.

그 이유는 **Hive** 는 쿼리 실행 전에 `transactions`와 `loan_payments` 테이블의 **파티션 정보**를 **MetaStore**에서 조회해야 하지만, `transactions` 테이블은 날짜별, 계좌별로 수천 개의 파티션을 가지고 있고, MetaStore는 RDBMS(MySQL)에서 이러한 파티션 정보를 순차적으로 조회하므로, 대규모 파티션에서 조회 시간이 급격히 늘어나기 때문입니다.

또, **MetaStore** 의 **Thrift 서버**는 단일 프로세스 기반으로 동작하기 때문에 동시 사용자 요청이 많게 되면, Connection Timeout 오류를 반환하기도 합니다.

무엇보다 MetaStore 는 RDBMS 와 연동하여 저장된 메타데이터를 사용하기 때문에 Connection Pool 크기에 따라 문제가 생기기도 하며, RDBMS 의 트랜잭션 처리 속도가 느려지게 됩니다.

쿼리가 MetaStore에서 필요한 정보를 가져오지 못하면, **Hive** 는 데이터 처리를 시작하지 못하기 때문에 위와 같은 문제가 발생 할 수 있습니다.

<br>

### 🧊 1.3. Hive 의 한계 : Schema 확장성의 한계
---

**세 번째 예시입니다.**

은행에서 데이터를 **Hive** 에 저장하는데, 고객이 거래를 한 지역별로 파티션을 나누어 저장하고, 기존 스키마는 아래와 같이 설정되어 있습니다.

```sql
CREATE TABLE card_transactions (
    transaction_id STRING,
    customer_id STRING,
    transaction_date DATE,
    amount DOUBLE
)
PARTITIONED BY (region STRING);
```

이 테이블은 마케팅 팀에서 고객의 지역별 소비 패턴을 분석하는 데 사용되고 있습니다.

그런데, 뭔가 요구 사항이 들어옵니다.

**첫 번째 요구 사항**은 **거래에 사용된 카드의 종류(예: 신용카드, 체크카드)를 추가하라는 요청**입니다. **두 번째**는 **지역 파티션 외에 연도별 파티션도 추가**하라는 요구입니다.

이를 구현하기 위해 스키마를 확장하고 파티션을 변경하려고 합니다. 하지만 Hive의 특성 때문에 여러 문제가 발생합니다.

일단 첫 번째 요구사항을 해결하기 위해, 스키마에 `card_type` 컬럼을 추가했습니다.

```sql
ALTER TABLE card_transactions
ADD COLUMNS (card_type STRING);
```

그런데 **Hive** 는 기존 데이터를 변경하지 않습니다. 새롭게 적재된 데이터만 `card_type` 정보를 포함하고, 기존 데이터는 이 컬럼에 대해 `NULL` 값을 갖습니다.

이로 인해 마케팅 팀은 동일한 테이블을 조회하면서 일부 데이터에는 카드 종류가 표시되고, 나머지는 `NULL`로 나옵니다. 분석 결과가 일관되지 않게 되어 혼란을 초래합니다.

그래서 파티션을 변경하는 작업을 실행하고자 합니다.

하지만 **Hive** 는 동적으로 파티션을 변경할 수 있는 기능이 제한적입니다.

기존 데이터에 새로운 연도별 파티션을 추가하려면, 데이터를 추출한 후 새로 생성된 테이블에 다시 적재해야 합니다. 이 과정에서 시간이 많이 소요되었고, 작업 도중 시스템이 과부하로 느려지는 문제가 발생했습니다.

추가로, 새로운 파티션 구조를 적용하는 동안 일부 쿼리가 기존 파티션 구조를 참조하면서 오류를 발생시켰습니다. 즉, 파티션 변경 과정에서 일시적으로 데이터 접근에 제한이 생겼습니다.

그리고 파티션을 변경하는 작업 중에, 무슨 일이 생길 수 있으니 백업 데이터를 만들어 저장한 후, 파티션 변경 작업을 시작함에 따라 추가적인 시간과 자원이 소모가 되었습니다.

이러한 문제 때문에, 스키마를 확장하거나, 파티션을 변경하는 요구사항에 대한 거부감이 생기게 되었습니다.

<br>

### 🧊 1.4. Hive 의 한계 : 기타 한계점
---

그 외에도 시간이 지남에 따라 데이터의 양이 폭발적으로 증가하면서, 디렉터리와 파일을 직접 스캔하는 형식으로 관리하는 **Hive** 에서는 조회 성능이 나빠지는 문제가 발견되기도 하였고,

잘못된 데이터가 덮어쓰여졌지만, 데이터를 **롤백**할 방법이 없기에 데이터를 다시 적재해야 하는 문제가 발견되기도 하였습니다.

그리고 파티션 필터링의 비효율성도 발견되기도 하였습니다.

파티션 필터링의 비효율성을 간단히 설명드리면, 

```sql
CREATE TABLE card_transactions (
    transaction_id STRING,
    customer_id STRING,
    transaction_date DATE,
    amount DOUBLE
)
PARTITIONED BY (year INT, region STRING);
```

이러한 쿼리문이 있을 때, 

```sql
SELECT * 
FROM card_transactions
WHERE customer_id = 'CUST12345';
```

이렇게 **고객ID** 로 조회를 할 경우, **고객ID** 는 파티션으로 지정되어있지 않기 때문에 **FULL SCAN** 작업을 거쳐 성능이 느려지게 됩니다.

이러한 단점들을 보완하기 위해 **파일 목록을 메타데이터로 사용하는 테이블 포멧 방식들이 생겨나기 시작하였습니다.** 

<br>

### 🧊 1.5. Hive 의 한계를 극복하기 위한 새로운 테이블 포멧 방식의 등장
---

**그러면 파일 목록을 메타데이터로 사용하는 테이블 포멧 방식이 뭘까요?**

이 접근 방식은 테이블을 디렉터리가 아닌 **파일 집합으로 구성**하며, 쿼리 엔진이 데이터를 효율적으로 처리할 수 있도록 도와줍니다. 이 방식은 전통적으로 디렉토리 구조를 기반으로 테이블을 정의하던 방식과는 차별화됩니다.

새로운 데이터가 추가되거나 기존 데이터가 수정될 경우, 변경된 파일 목록이 메타데이터에 업데이트 되며, 쿼리 엔진은 메타데이터를 먼저 읽어, 쿼리 실행에 필요한 정확한 데이터 파일들만 접근한다는 특징이 있습니다. 대표적으로는  **Apache Iceberg, Apache Hudi, Delta Lake** 가 있습니다.

**자, 그럼 오늘 발표 주제인 Apache Iceberg는, 대체 어떤 특징이 있길래 Hive 의 단점을 모두 보완 할 수 있는 특징을 가지고 있을까요?** 그리고, 많은 기업들이 **Hudi** 나 **Delta Lake** 대신 **Apache Iceberg** 를 선택하는 이유가 무엇일까요?

저는 **Apache Iceberg** 에 대해 공부하고 조사하면서 이러한 메타 데이터 형식의 테이블 포맷에는 여러가지 개발 철학이 있고, 수 많은 장점이 있다는 것을 알았습니다. 그리고, 저는 그걸 **C.P.C.S** **네 가지**의 중심적인 개발 철학과 **일곱 가지**의 큰 장점으로 정리를 하였습니다.

<br>

### 🧊 1.6. Iceberg 의 네 가지 핵심 철학
---

**Apache Iceberg** 의 개발 철학 다섯 가지는 **“일관성”, “성능”, “편의성”, “확장성”**  입니다.

**1. 일관성 (Consistency)**

- 데이터가 항상 예상된 상태를 유지하도록 설계되었습니다. **Iceberg**는 **ACID** 트랜잭션을 기본적으로 지원하며, 이를 통해 데이터 작업의 일관성을 보장합니다. 예를 들어, 여러 작업이 동시에 이루어져도 데이터의 손상이나 충돌이 발생하지 않도록 합니다.

**2. 성능 (Performance)**

- Iceberg는 대규모 데이터 세트를 효율적으로 처리할 수 있도록 최적화되었습니다. 쿼리 성능을 높이기 위해 파일 스키핑, 파티셔닝, 정렬, Z-order와 같은 다양한 최적화 기법을 제공합니다.
- 또한, Hive에서는 **파일과 디렉터리를 모두 열거**하면서 쿼리 계획 수립에 시간이 많이 소요됩니다. 하지만 Iceberg는 **메타데이터**를 활용하여 필요한 파일만 조회하고, 쿼리 성능을 최적화 합니다.

**3. 편의성 (Convenience)**

- Iceberg는 다양한 컴퓨팅 엔진(예: Apache Spark, Apache Flink, Dremio 등)과 호환되어 사용자가 친숙한 환경에서 작업할 수 있도록 합니다. 또한, 강력한 메타데이터 관리 기능을 통해 데이터 관리와 분석을 단순화합니다.
- Hive에서는 사용자가 **파티션된 컬럼을 직접 필터링**해야 하는 번거로움이 있었습니다. 예를 들어, `timestamp`로 필터링할 때 이를 `month` 파티션으로 매핑해야 했습니다. 그러나 Iceberg는 사용자가 **직관적인 쿼리**만 작성해도 자동으로 파티셔닝을 활용할 수 있도록 설계되었습니다. 예를들면 자주 사용하는 컬럼에 대한 자동 파티셔닝을 지원합니다.

**4. 확장성 (Scalability)**

- Hive에서는 **스키마를 변경하거나 파티션 방식을 수정**할 때 테이블 전체를 다시 작성해야 합니다. 하지만 **Iceberg**는 **스키마 진화와 파티션 재구성**을 안전하게 지원하여 기존 데이터를 다시 작성하지 않아도 됩니다. 즉, **스키마와 파티션을 유연하게 변경**할 수 있어 데이터 모델의 확장성을 보장합니다.

이러한 네 가지 개발 철학은 **Apache Iceberg**가 단순히 데이터 저장 및 관리의 도구를 넘어, 현대 데이터 플랫폼에서 필수적인 역할을 수행할 수 있는 이유를 잘 보여줍니다. **Iceberg**는 데이터 엔지니어와 분석가가 점점 더 복잡해지는 데이터 환경에서도 신뢰성과 효율성을 유지하면서 작업을 수행할 수 있도록 설계되었습니다.

<br>

### 🧊 1.7. Iceberg 의 일곱 가지 주요 장점
---

이제 **Apache Iceberg**가 제공하는 **일곱 가지 주요 장점**에 대해 살펴보겠습니다. 이를 통해 Iceberg가 어떻게 **데이터 레이크하우스**의 강력한 기반으로 자리 잡고 있는지 더욱 구체적으로 이해할 수 있을 것입니다.

**아이스버그의** 첫 번째 장점은 **ACID 기능**을 완벽하게 지원해줌으로 데이터 레이크에서 신뢰성과 일관성을 보장하는 핵심 기능 역할을 합니다.